{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b49190e",
   "metadata": {},
   "source": [
    "# Unballanced dataset model implementation\n",
    "\n",
    "    \n",
    "### Boosting alghoritms: \n",
    "    XGBoost\n",
    "    AdaBoost\n",
    "    Gradient Boosting Machine\n",
    "    Optimized light gradient boosting \n",
    "    CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb9794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2417b810",
   "metadata": {},
   "source": [
    "## Unballanced dataset Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7304c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors  \n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867e6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/data3_synthetic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1de8421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.223811</td>\n",
       "      <td>-0.997202</td>\n",
       "      <td>-0.760048</td>\n",
       "      <td>-0.368115</td>\n",
       "      <td>-0.989130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.659099</td>\n",
       "      <td>-0.997189</td>\n",
       "      <td>0.976920</td>\n",
       "      <td>-0.316844</td>\n",
       "      <td>-0.989130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.811941</td>\n",
       "      <td>-0.997146</td>\n",
       "      <td>-0.996419</td>\n",
       "      <td>-0.726818</td>\n",
       "      <td>-0.989130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.354844</td>\n",
       "      <td>-0.997134</td>\n",
       "      <td>0.645444</td>\n",
       "      <td>0.749650</td>\n",
       "      <td>-0.989130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.113514</td>\n",
       "      <td>-0.997126</td>\n",
       "      <td>-0.628333</td>\n",
       "      <td>0.983777</td>\n",
       "      <td>-0.989130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class       V1        V2        V3        V4        V5\n",
       "0      0 0.223811 -0.997202 -0.760048 -0.368115 -0.989130\n",
       "1      0 0.659099 -0.997189  0.976920 -0.316844 -0.989130\n",
       "2      0 1.811941 -0.997146 -0.996419 -0.726818 -0.989130\n",
       "3      0 0.354844 -0.997134  0.645444  0.749650 -0.989130\n",
       "4      0 0.113514 -0.997126 -0.628333  0.983777 -0.989130"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719f1085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting Training and testing data\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8aabbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9150af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f67bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [ 350197  350198  350199 ... 1754152 1754153 1754154] Test: [     0      1      2 ... 424727 425176 425184]\n",
      "Train: [      0       1       2 ... 1754152 1754153 1754154] Test: [350197 350198 350199 ... 768566 768653 768685]\n",
      "Train: [      0       1       2 ... 1754152 1754153 1754154] Test: [ 701101  701102  701103 ... 1095208 1095343 1095476]\n",
      "Train: [      0       1       2 ... 1754152 1754153 1754154] Test: [1052163 1052164 1052165 ... 1424801 1424859 1425018]\n",
      "Train: [      0       1       2 ... 1424801 1424859 1425018] Test: [1403110 1403111 1403112 ... 1754152 1754153 1754154]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Label Distributions: \n",
      "\n",
      "[0.9916313 0.0083687]\n",
      "[0.99162845 0.00837155]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Check the Distribution of the labels\n",
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = original_Xtest.values\n",
    "original_ytrain = original_ytrain.values\n",
    "original_ytest = original_ytest.values\n",
    "\n",
    "# Check to see if the distribution of the test and train labels is similar.\n",
    "train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\n",
    "test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n",
    "print('-' * 100)\n",
    "\n",
    "print('Label Distributions: \\n')\n",
    "print(train_counts_label/ len(original_ytrain))\n",
    "print(test_counts_label/ len(original_ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec72731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd12aff7",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "by including tweaking for max_depth and n_estimators alongside learning_rate, we'll set up a nested loop to iterate over combinations of these parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d1576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e820c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.01, Depth: 3, Estimators: 20 4.003005027770996\n",
      "LR: 0.01, Depth: 3, Estimators: 50 5.163248062133789\n",
      "LR: 0.01, Depth: 3, Estimators: 100 5.816546440124512\n",
      "LR: 0.01, Depth: 3, Estimators: 200 8.84053087234497\n",
      "LR: 0.01, Depth: 3, Estimators: 500 18.153380632400513\n",
      "LR: 0.01, Depth: 3, Estimators: 1000 34.31721520423889\n",
      "LR: 0.01, Depth: 6, Estimators: 20 3.9422965049743652\n",
      "LR: 0.01, Depth: 6, Estimators: 50 5.948397636413574\n",
      "LR: 0.01, Depth: 6, Estimators: 100 7.727770566940308\n",
      "LR: 0.01, Depth: 6, Estimators: 200 12.981003999710083\n",
      "LR: 0.01, Depth: 6, Estimators: 500 31.947895765304565\n",
      "LR: 0.01, Depth: 6, Estimators: 1000 81.12107515335083\n",
      "LR: 0.01, Depth: 9, Estimators: 20 4.118523836135864\n",
      "LR: 0.01, Depth: 9, Estimators: 50 7.19537091255188\n",
      "LR: 0.01, Depth: 9, Estimators: 100 10.883767366409302\n",
      "LR: 0.01, Depth: 9, Estimators: 200 21.810601234436035\n",
      "LR: 0.01, Depth: 9, Estimators: 500 45.25473976135254\n",
      "LR: 0.01, Depth: 9, Estimators: 1000 85.99015927314758\n",
      "LR: 0.1, Depth: 3, Estimators: 20 3.8319456577301025\n",
      "LR: 0.1, Depth: 3, Estimators: 50 4.698131799697876\n",
      "LR: 0.1, Depth: 3, Estimators: 100 6.639829397201538\n",
      "LR: 0.1, Depth: 3, Estimators: 200 11.77175498008728\n",
      "LR: 0.1, Depth: 3, Estimators: 500 22.48558235168457\n",
      "LR: 0.1, Depth: 3, Estimators: 1000 39.33057475090027\n",
      "LR: 0.1, Depth: 6, Estimators: 20 4.734775066375732\n",
      "LR: 0.1, Depth: 6, Estimators: 50 5.708115816116333\n",
      "LR: 0.1, Depth: 6, Estimators: 100 9.178113222122192\n",
      "LR: 0.1, Depth: 6, Estimators: 200 14.438083410263062\n",
      "LR: 0.1, Depth: 6, Estimators: 500 28.18867516517639\n",
      "LR: 0.1, Depth: 6, Estimators: 1000 52.226832151412964\n",
      "LR: 0.1, Depth: 9, Estimators: 20 5.271998405456543\n",
      "LR: 0.1, Depth: 9, Estimators: 50 6.942102909088135\n",
      "LR: 0.1, Depth: 9, Estimators: 100 10.577470541000366\n",
      "LR: 0.1, Depth: 9, Estimators: 200 17.33904528617859\n",
      "LR: 0.1, Depth: 9, Estimators: 500 42.156620502471924\n",
      "LR: 0.1, Depth: 9, Estimators: 1000 72.54800868034363\n",
      "LR: 0.3, Depth: 3, Estimators: 20 4.675968647003174\n",
      "LR: 0.3, Depth: 3, Estimators: 50 4.88505220413208\n",
      "LR: 0.3, Depth: 3, Estimators: 100 6.454818487167358\n",
      "LR: 0.3, Depth: 3, Estimators: 200 9.812272548675537\n",
      "LR: 0.3, Depth: 3, Estimators: 500 18.830254316329956\n",
      "LR: 0.3, Depth: 3, Estimators: 1000 36.679358959198\n",
      "LR: 0.3, Depth: 6, Estimators: 20 5.655317068099976\n",
      "LR: 0.3, Depth: 6, Estimators: 50 6.474722862243652\n",
      "LR: 0.3, Depth: 6, Estimators: 100 11.883214235305786\n",
      "LR: 0.3, Depth: 6, Estimators: 200 17.702008724212646\n",
      "LR: 0.3, Depth: 6, Estimators: 500 37.589900732040405\n",
      "LR: 0.3, Depth: 6, Estimators: 1000 51.98598289489746\n",
      "LR: 0.3, Depth: 9, Estimators: 20 5.275449275970459\n",
      "LR: 0.3, Depth: 9, Estimators: 50 7.422122001647949\n",
      "LR: 0.3, Depth: 9, Estimators: 100 10.152802467346191\n",
      "LR: 0.3, Depth: 9, Estimators: 200 16.778358459472656\n",
      "LR: 0.3, Depth: 9, Estimators: 500 38.60346555709839\n",
      "LR: 0.3, Depth: 9, Estimators: 1000 80.18890380859375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# Define ranges for the parameters to test\n",
    "learning_rates = [0.01, 0.1, 0.3]\n",
    "max_depths = [3, 6, 9]\n",
    "n_estimators = [20, 50, 100, 200, 500, 1000]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over the combinations of learning_rates, max_depths, and n_estimators\n",
    "for lr in learning_rates:\n",
    "    for depth in max_depths:\n",
    "        for n_est in n_estimators:\n",
    "            start_time = time.time()  # Start timing\n",
    "            \n",
    "            # Instantiate and fit the XGBoost classifier\n",
    "            xgb_classifier = xgb.XGBClassifier(learning_rate=lr, max_depth=depth, n_estimators=n_est,\n",
    "                                               use_label_encoder=False, eval_metric='logloss')\n",
    "            xgb_classifier.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict and evaluate on training data\n",
    "            y_train_pred = xgb_classifier.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "            train_f1 = f1_score(y_train, y_train_pred)\n",
    "            train_recall = recall_score(y_train, y_train_pred)\n",
    "            train_precision = precision_score(y_train, y_train_pred)\n",
    "            \n",
    "            # Predict and evaluate on testing data\n",
    "            y_test_pred = xgb_classifier.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            test_f1 = f1_score(y_test, y_test_pred)\n",
    "            test_recall = recall_score(y_test, y_test_pred)\n",
    "            test_precision = precision_score(y_test, y_test_pred)\n",
    "            \n",
    "            # Calculate elapsed time\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            \n",
    "            # Append training and testing results separately, including parameter values and execution time\n",
    "            params = f'LR: {lr}, Depth: {depth}, Estimators: {n_est}'\n",
    "            \n",
    "            print(params, elapsed_time)\n",
    "            \n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Training',\n",
    "                'Accuracy': train_accuracy,\n",
    "                'F1 Score': train_f1,\n",
    "                'Recall': train_recall,\n",
    "                'Precision': train_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Testing',\n",
    "                'Accuracy': test_accuracy,\n",
    "                'F1 Score': test_f1,\n",
    "                'Recall': test_recall,\n",
    "                'Precision': test_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4af2cb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Data Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Execution Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 20</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.991569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.003005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 20</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.991876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.003005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 50</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.991569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 50</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.991876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 100</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.991569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.816546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Parameters Data Split  Accuracy  F1 Score  \\\n",
       "0   LR: 0.01, Depth: 3, Estimators: 20   Training  0.991569  0.000000   \n",
       "1   LR: 0.01, Depth: 3, Estimators: 20    Testing  0.991876  0.000000   \n",
       "2   LR: 0.01, Depth: 3, Estimators: 50   Training  0.991569  0.000000   \n",
       "3   LR: 0.01, Depth: 3, Estimators: 50    Testing  0.991876  0.000000   \n",
       "4  LR: 0.01, Depth: 3, Estimators: 100   Training  0.991569  0.000000   \n",
       "\n",
       "    Recall  Precision  Execution Time (s)  \n",
       "0 0.000000   0.000000            4.003005  \n",
       "1 0.000000   0.000000            4.003005  \n",
       "2 0.000000   0.000000            5.163248  \n",
       "3 0.000000   0.000000            5.163248  \n",
       "4 0.000000   0.000000            5.816546  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_excel('data3_results/XGBoost_results.xlsx', index=False)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdccbef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f285ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eac49d95",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "To experiment with the AdaBoost algorithm and tweak its parameters, we can adjust the number of estimators (n_estimators) and the learning rate (learning_rate). These are two key parameters for AdaBoost that influence the performance and complexity of the resulting model. The n_estimators parameter controls the number of sequential models to be added to correct the errors of the previous models, while learning_rate scales the contribution of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5611c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 10, LR: 0.01 26.956761121749878\n",
      "Estimators: 10, LR: 0.1 24.028055906295776\n",
      "Estimators: 10, LR: 0.5 24.49956178665161\n",
      "Estimators: 10, LR: 1 24.55051279067993\n",
      "Estimators: 25, LR: 0.01 54.94986534118652\n",
      "Estimators: 25, LR: 0.1 54.04945230484009\n",
      "Estimators: 25, LR: 0.5 56.36599326133728\n",
      "Estimators: 25, LR: 1 56.06926774978638\n",
      "Estimators: 50, LR: 0.01 109.1175627708435\n",
      "Estimators: 50, LR: 0.1 112.29208755493164\n",
      "Estimators: 50, LR: 0.5 112.23736095428467\n",
      "Estimators: 50, LR: 1 112.10819983482361\n",
      "Estimators: 100, LR: 0.01 216.1755862236023\n",
      "Estimators: 100, LR: 0.1 216.39499497413635\n",
      "Estimators: 100, LR: 0.5 219.55863070487976\n",
      "Estimators: 100, LR: 1 224.14096212387085\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# Define ranges for the parameters to test\n",
    "n_estimators_list = [10, 25, 50, 100] #, 500, 1000, 5000] #Too slow to run all. At 1000 took 4 hours and crashed.\n",
    "learning_rates_list = [0.01, 0.1, 0.5, 1] #, 2]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over the combinations of n_estimators and learning_rates\n",
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rates_list:\n",
    "        start_time = time.time()  # Start timing\n",
    "        \n",
    "        # Instantiate and fit the AdaBoost classifier\n",
    "        ada_classifier = AdaBoostClassifier(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "        ada_classifier.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and evaluate on training data\n",
    "        y_train_pred = ada_classifier.predict(X_train)\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        train_f1 = f1_score(y_train, y_train_pred)\n",
    "        train_recall = recall_score(y_train, y_train_pred)\n",
    "        train_precision = precision_score(y_train, y_train_pred)\n",
    "        \n",
    "        # Predict and evaluate on testing data\n",
    "        y_test_pred = ada_classifier.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        test_f1 = f1_score(y_test, y_test_pred)\n",
    "        test_recall = recall_score(y_test, y_test_pred)\n",
    "        test_precision = precision_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        # Append training and testing results separately, including parameter values and execution time\n",
    "        params = f'Estimators: {n_estimators}, LR: {learning_rate}'\n",
    "        print(params, elapsed_time)\n",
    "        results.append({\n",
    "            'Parameters': params,\n",
    "            'Data Split': 'Training',\n",
    "            'Accuracy': train_accuracy,\n",
    "            'F1 Score': train_f1,\n",
    "            'Recall': train_recall,\n",
    "            'Precision': train_precision,\n",
    "            'Execution Time (s)': elapsed_time\n",
    "        })\n",
    "        results.append({\n",
    "            'Parameters': params,\n",
    "            'Data Split': 'Testing',\n",
    "            'Accuracy': test_accuracy,\n",
    "            'F1 Score': test_f1,\n",
    "            'Recall': test_recall,\n",
    "            'Precision': test_precision,\n",
    "            'Execution Time (s)': elapsed_time\n",
    "        })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2116cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Data Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Execution Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estimators: 10, LR: 0.01</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.993435</td>\n",
       "      <td>0.362378</td>\n",
       "      <td>0.221283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.956761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Estimators: 10, LR: 0.01</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.993704</td>\n",
       "      <td>0.367230</td>\n",
       "      <td>0.224912</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.956761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Estimators: 10, LR: 0.1</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.993435</td>\n",
       "      <td>0.362378</td>\n",
       "      <td>0.221283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.028056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estimators: 10, LR: 0.1</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.993704</td>\n",
       "      <td>0.367230</td>\n",
       "      <td>0.224912</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.028056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estimators: 10, LR: 0.5</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.993435</td>\n",
       "      <td>0.362378</td>\n",
       "      <td>0.221283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.499562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Parameters Data Split  Accuracy  F1 Score   Recall  \\\n",
       "0  Estimators: 10, LR: 0.01   Training  0.993435  0.362378 0.221283   \n",
       "1  Estimators: 10, LR: 0.01    Testing  0.993704  0.367230 0.224912   \n",
       "2   Estimators: 10, LR: 0.1   Training  0.993435  0.362378 0.221283   \n",
       "3   Estimators: 10, LR: 0.1    Testing  0.993704  0.367230 0.224912   \n",
       "4   Estimators: 10, LR: 0.5   Training  0.993435  0.362378 0.221283   \n",
       "\n",
       "   Precision  Execution Time (s)  \n",
       "0   1.000000           26.956761  \n",
       "1   1.000000           26.956761  \n",
       "2   1.000000           24.028056  \n",
       "3   1.000000           24.028056  \n",
       "4   1.000000           24.499562  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_excel('data3_results/AdaBoost_results.xlsx', index=False)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b052500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "724b3b8e",
   "metadata": {},
   "source": [
    "## AdaBoost with Decision Tree clacifier\n",
    "\n",
    "AdaBoost, as implemented in scikit-learn (AdaBoostClassifier), doesn't directly accept a max_depth parameter because AdaBoost can be used with various types of base estimators, not just decision trees. This is a frequent way of using AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0101ef94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 10, LR: 0.01, Depth: 3 57.369370460510254\n",
      "Estimators: 10, LR: 0.01, Depth: 5 88.89150857925415\n",
      "Estimators: 10, LR: 0.01, Depth: 7 121.49059724807739\n",
      "Estimators: 10, LR: 0.1, Depth: 3 55.72072649002075\n",
      "Estimators: 10, LR: 0.1, Depth: 5 87.91244196891785\n",
      "Estimators: 10, LR: 0.1, Depth: 7 119.1020143032074\n",
      "Estimators: 10, LR: 0.3, Depth: 3 57.55844783782959\n",
      "Estimators: 10, LR: 0.3, Depth: 5 86.01259350776672\n",
      "Estimators: 10, LR: 0.3, Depth: 7 123.87506103515625\n",
      "Estimators: 25, LR: 0.01, Depth: 3 140.37486243247986\n",
      "Estimators: 25, LR: 0.01, Depth: 5 216.529625415802\n",
      "Estimators: 25, LR: 0.01, Depth: 7 291.60878443717957\n",
      "Estimators: 25, LR: 0.1, Depth: 3 139.96478080749512\n",
      "Estimators: 25, LR: 0.1, Depth: 5 222.31930565834045\n",
      "Estimators: 25, LR: 0.1, Depth: 7 300.19666814804077\n",
      "Estimators: 25, LR: 0.3, Depth: 3 140.36984634399414\n",
      "Estimators: 25, LR: 0.3, Depth: 5 220.21723890304565\n",
      "Estimators: 25, LR: 0.3, Depth: 7 298.06032252311707\n",
      "Estimators: 50, LR: 0.01, Depth: 3 268.9277777671814\n",
      "Estimators: 50, LR: 0.01, Depth: 5 421.53652834892273\n",
      "Estimators: 50, LR: 0.01, Depth: 7 583.7275171279907\n",
      "Estimators: 50, LR: 0.1, Depth: 3 273.5122470855713\n",
      "Estimators: 50, LR: 0.1, Depth: 5 427.98105812072754\n",
      "Estimators: 50, LR: 0.1, Depth: 7 601.344034910202\n",
      "Estimators: 50, LR: 0.3, Depth: 3 276.6678795814514\n",
      "Estimators: 50, LR: 0.3, Depth: 5 440.84654998779297\n",
      "Estimators: 50, LR: 0.3, Depth: 7 585.6150770187378\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# Define ranges for the parameters to test\n",
    "n_estimators_list = [10, 25, 50] #, 500, 1000, 5000]\n",
    "learning_rates_list = [0.01, 0.1, 0.3]\n",
    "max_depths = [3, 5, 7]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over the combinations of n_estimators, learning_rates, and max_depths\n",
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rates_list:\n",
    "        for max_depth in max_depths:\n",
    "            start_time = time.time()  # Start timing\n",
    "            \n",
    "            # Create a DecisionTreeClassifier with the specified max_depth\n",
    "            base_estimator = DecisionTreeClassifier(max_depth=max_depth)\n",
    "            \n",
    "            # Instantiate and fit the AdaBoost classifier with the DecisionTree base estimator\n",
    "            ada_classifier = AdaBoostClassifier(\n",
    "                base_estimator=base_estimator,\n",
    "                n_estimators=n_estimators,\n",
    "                learning_rate=learning_rate\n",
    "            )\n",
    "            ada_classifier.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict and evaluate on training data\n",
    "            y_train_pred = ada_classifier.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "            train_f1 = f1_score(y_train, y_train_pred)\n",
    "            train_recall = recall_score(y_train, y_train_pred)\n",
    "            train_precision = precision_score(y_train, y_train_pred)\n",
    "            \n",
    "            # Predict and evaluate on testing data\n",
    "            y_test_pred = ada_classifier.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            test_f1 = f1_score(y_test, y_test_pred)\n",
    "            test_recall = recall_score(y_test, y_test_pred)\n",
    "            test_precision = precision_score(y_test, y_test_pred)\n",
    "            \n",
    "            # Calculate elapsed time\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            \n",
    "            # Append training and testing results separately, including parameter values and execution time\n",
    "            params = f'Estimators: {n_estimators}, LR: {learning_rate}, Depth: {max_depth}'\n",
    "            print(params, elapsed_time)\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Training',\n",
    "                'Accuracy': train_accuracy,\n",
    "                'F1 Score': train_f1,\n",
    "                'Recall': train_recall,\n",
    "                'Precision': train_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Testing',\n",
    "                'Accuracy': test_accuracy,\n",
    "                'F1 Score': test_f1,\n",
    "                'Recall': test_recall,\n",
    "                'Precision': test_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fe6710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('data3_results/AdaboostDT_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693661be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Was run in different instance on another similar computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2746e8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9524046",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machine\n",
    "\n",
    "To perform a similar parameter tweaking experiment with a Gradient Boosting Machine (GBM) using scikit-learn's GradientBoostingClassifier, we can iterate over combinations of n_estimators, learning_rate, and max_depth. These parameters are analogous to those adjusted in the AdaBoost and XGBoost, serving similar purposes:\n",
    "\n",
    "n_estimators: controls the number of sequential trees to be modeled.\n",
    "learning_rate: scales the contribution of each tree.\n",
    "max_depth: sets the maximum depth of each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b272ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 10, LR: 0.01, Depth: 3 50.11316227912903\n",
      "Estimators: 10, LR: 0.01, Depth: 6 96.05612015724182\n",
      "Estimators: 10, LR: 0.01, Depth: 9 146.7016384601593\n",
      "Estimators: 10, LR: 0.1, Depth: 3 51.65701341629028\n",
      "Estimators: 10, LR: 0.1, Depth: 6 100.11393427848816\n",
      "Estimators: 10, LR: 0.1, Depth: 9 150.24624872207642\n",
      "Estimators: 10, LR: 0.3, Depth: 3 50.959155321121216\n",
      "Estimators: 10, LR: 0.3, Depth: 6 101.6550235748291\n",
      "Estimators: 10, LR: 0.3, Depth: 9 150.32666325569153\n",
      "Estimators: 50, LR: 0.01, Depth: 3 261.01782274246216\n",
      "Estimators: 50, LR: 0.01, Depth: 6 522.9441232681274\n",
      "Estimators: 50, LR: 0.01, Depth: 9 778.2255091667175\n",
      "Estimators: 50, LR: 0.1, Depth: 3 258.34352827072144\n",
      "Estimators: 50, LR: 0.1, Depth: 6 497.89626002311707\n",
      "Estimators: 50, LR: 0.1, Depth: 9 746.8027191162109\n",
      "Estimators: 50, LR: 0.3, Depth: 3 250.33263516426086\n",
      "Estimators: 50, LR: 0.3, Depth: 6 507.9370141029358\n",
      "Estimators: 50, LR: 0.3, Depth: 9 909.3066816329956\n",
      "Estimators: 100, LR: 0.01, Depth: 3 596.6135818958282\n",
      "Estimators: 100, LR: 0.01, Depth: 6 1177.2138667106628\n",
      "Estimators: 100, LR: 0.01, Depth: 9 1747.402466058731\n",
      "Estimators: 100, LR: 0.1, Depth: 3 589.2555627822876\n",
      "Estimators: 100, LR: 0.1, Depth: 6 1168.223248720169\n",
      "Estimators: 100, LR: 0.1, Depth: 9 1805.9199481010437\n",
      "Estimators: 100, LR: 0.3, Depth: 3 586.2127850055695\n",
      "Estimators: 100, LR: 0.3, Depth: 6 1170.5583746433258\n",
      "Estimators: 100, LR: 0.3, Depth: 9 1825.565761089325\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# Define ranges for the parameters to test\n",
    "n_estimators_list = [10, 50, 100]\n",
    "learning_rates_list = [0.01, 0.1, 0.3]\n",
    "max_depths = [3, 6, 9]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over the combinations of n_estimators, learning_rates, and max_depths\n",
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rates_list:\n",
    "        for max_depth in max_depths:\n",
    "            start_time = time.time()  # Start timing\n",
    "            \n",
    "            # Instantiate and fit the GradientBoostingClassifier\n",
    "            gbm_classifier = GradientBoostingClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                learning_rate=learning_rate,\n",
    "                max_depth=max_depth\n",
    "            )\n",
    "            gbm_classifier.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict and evaluate on training data\n",
    "            y_train_pred = gbm_classifier.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "            train_f1 = f1_score(y_train, y_train_pred)\n",
    "            train_recall = recall_score(y_train, y_train_pred)\n",
    "            train_precision = precision_score(y_train, y_train_pred)\n",
    "            \n",
    "            # Predict and evaluate on testing data\n",
    "            y_test_pred = gbm_classifier.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            test_f1 = f1_score(y_test, y_test_pred)\n",
    "            test_recall = recall_score(y_test, y_test_pred)\n",
    "            test_precision = precision_score(y_test, y_test_pred)\n",
    "            \n",
    "            # Calculate elapsed time\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            \n",
    "            # Append training and testing results separately, including parameter values and execution time\n",
    "            params = f'Estimators: {n_estimators}, LR: {learning_rate}, Depth: {max_depth}'\n",
    "            print(params, elapsed_time)\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Training',\n",
    "                'Accuracy': train_accuracy,\n",
    "                'F1 Score': train_f1,\n",
    "                'Recall': train_recall,\n",
    "                'Precision': train_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Testing',\n",
    "                'Accuracy': test_accuracy,\n",
    "                'F1 Score': test_f1,\n",
    "                'Recall': test_recall,\n",
    "                'Precision': test_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48458340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Data Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Execution Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estimators: 10, LR: 0.01, Depth: 3</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.991569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.113162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Estimators: 10, LR: 0.01, Depth: 3</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.991876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.113162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Estimators: 10, LR: 0.01, Depth: 6</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.991569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.056120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estimators: 10, LR: 0.01, Depth: 6</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.991876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.056120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estimators: 10, LR: 0.01, Depth: 9</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.991569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>146.701638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Parameters Data Split  Accuracy  F1 Score   Recall  \\\n",
       "0  Estimators: 10, LR: 0.01, Depth: 3   Training  0.991569  0.000000 0.000000   \n",
       "1  Estimators: 10, LR: 0.01, Depth: 3    Testing  0.991876  0.000000 0.000000   \n",
       "2  Estimators: 10, LR: 0.01, Depth: 6   Training  0.991569  0.000000 0.000000   \n",
       "3  Estimators: 10, LR: 0.01, Depth: 6    Testing  0.991876  0.000000 0.000000   \n",
       "4  Estimators: 10, LR: 0.01, Depth: 9   Training  0.991569  0.000000 0.000000   \n",
       "\n",
       "   Precision  Execution Time (s)  \n",
       "0   0.000000           50.113162  \n",
       "1   0.000000           50.113162  \n",
       "2   0.000000           96.056120  \n",
       "3   0.000000           96.056120  \n",
       "4   0.000000          146.701638  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_excel('data3_results/GBM_results.xlsx', index=False)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9292b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79f2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb42b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7e990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c887899e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a8d4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da7830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586468f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638a95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76116dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad37cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086b639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ceda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af484487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6217910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
