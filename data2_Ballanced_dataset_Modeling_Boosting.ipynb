{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b49190e",
   "metadata": {},
   "source": [
    "# Ballanced dataset model implementation\n",
    "\n",
    "    \n",
    "### Boosting alghoritms: \n",
    "    XGBoost\n",
    "    AdaBoost\n",
    "    Gradient Boosting Machine\n",
    "    Optimized light gradient boosting\n",
    "    CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb9794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2417b810",
   "metadata": {},
   "source": [
    "## Ballanced dataset Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7304c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors  \n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "867e6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/data2_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1de8421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_amount</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.496764</td>\n",
       "      <td>-0.260648</td>\n",
       "      <td>-0.469648</td>\n",
       "      <td>2.496266</td>\n",
       "      <td>-0.083724</td>\n",
       "      <td>0.129681</td>\n",
       "      <td>0.732898</td>\n",
       "      <td>0.519014</td>\n",
       "      <td>-0.130006</td>\n",
       "      <td>0.727159</td>\n",
       "      <td>0.637735</td>\n",
       "      <td>-0.987020</td>\n",
       "      <td>0.293438</td>\n",
       "      <td>-0.941386</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>1.804879</td>\n",
       "      <td>0.215598</td>\n",
       "      <td>0.512307</td>\n",
       "      <td>0.333644</td>\n",
       "      <td>0.124270</td>\n",
       "      <td>0.091202</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>0.217606</td>\n",
       "      <td>-0.134794</td>\n",
       "      <td>0.165959</td>\n",
       "      <td>0.126280</td>\n",
       "      <td>-0.434824</td>\n",
       "      <td>-0.081230</td>\n",
       "      <td>-0.151045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.458942</td>\n",
       "      <td>0.985100</td>\n",
       "      <td>-0.356045</td>\n",
       "      <td>0.558056</td>\n",
       "      <td>-0.429654</td>\n",
       "      <td>0.277140</td>\n",
       "      <td>0.428605</td>\n",
       "      <td>0.406466</td>\n",
       "      <td>-0.133118</td>\n",
       "      <td>0.347452</td>\n",
       "      <td>0.529808</td>\n",
       "      <td>0.140107</td>\n",
       "      <td>1.564246</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.627719</td>\n",
       "      <td>0.706121</td>\n",
       "      <td>0.789188</td>\n",
       "      <td>0.403810</td>\n",
       "      <td>0.201799</td>\n",
       "      <td>-0.340687</td>\n",
       "      <td>-0.233984</td>\n",
       "      <td>-0.194936</td>\n",
       "      <td>-0.605761</td>\n",
       "      <td>0.079469</td>\n",
       "      <td>-0.577395</td>\n",
       "      <td>0.190090</td>\n",
       "      <td>0.296503</td>\n",
       "      <td>-0.248052</td>\n",
       "      <td>-0.064512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.794279</td>\n",
       "      <td>-0.260272</td>\n",
       "      <td>-0.949385</td>\n",
       "      <td>1.728538</td>\n",
       "      <td>-0.457986</td>\n",
       "      <td>0.074062</td>\n",
       "      <td>1.419481</td>\n",
       "      <td>0.743511</td>\n",
       "      <td>-0.095576</td>\n",
       "      <td>-0.261297</td>\n",
       "      <td>0.690708</td>\n",
       "      <td>-0.272985</td>\n",
       "      <td>0.659201</td>\n",
       "      <td>0.805173</td>\n",
       "      <td>0.616874</td>\n",
       "      <td>3.069025</td>\n",
       "      <td>-0.577514</td>\n",
       "      <td>0.886526</td>\n",
       "      <td>0.239442</td>\n",
       "      <td>-2.366079</td>\n",
       "      <td>0.361652</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.702906</td>\n",
       "      <td>0.945045</td>\n",
       "      <td>-1.154666</td>\n",
       "      <td>-0.605564</td>\n",
       "      <td>-0.312895</td>\n",
       "      <td>-0.300258</td>\n",
       "      <td>-0.244718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.554667</td>\n",
       "      <td>-0.152152</td>\n",
       "      <td>-0.508959</td>\n",
       "      <td>1.746840</td>\n",
       "      <td>-1.090178</td>\n",
       "      <td>0.249486</td>\n",
       "      <td>1.143312</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>-0.065130</td>\n",
       "      <td>-0.205698</td>\n",
       "      <td>0.575231</td>\n",
       "      <td>-0.752581</td>\n",
       "      <td>0.737483</td>\n",
       "      <td>0.592994</td>\n",
       "      <td>0.559535</td>\n",
       "      <td>-0.697664</td>\n",
       "      <td>-0.030669</td>\n",
       "      <td>0.242629</td>\n",
       "      <td>2.178616</td>\n",
       "      <td>-1.345060</td>\n",
       "      <td>-0.378223</td>\n",
       "      <td>-0.146927</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>-0.214048</td>\n",
       "      <td>-1.893131</td>\n",
       "      <td>1.003963</td>\n",
       "      <td>-0.515950</td>\n",
       "      <td>-0.165316</td>\n",
       "      <td>0.048424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.187692</td>\n",
       "      <td>-0.206820</td>\n",
       "      <td>-0.165280</td>\n",
       "      <td>1.527053</td>\n",
       "      <td>-0.448293</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.530549</td>\n",
       "      <td>0.658849</td>\n",
       "      <td>-0.212660</td>\n",
       "      <td>1.049921</td>\n",
       "      <td>0.968046</td>\n",
       "      <td>-1.203171</td>\n",
       "      <td>1.029577</td>\n",
       "      <td>1.439310</td>\n",
       "      <td>0.241454</td>\n",
       "      <td>0.153008</td>\n",
       "      <td>0.224538</td>\n",
       "      <td>0.366466</td>\n",
       "      <td>0.291782</td>\n",
       "      <td>0.445317</td>\n",
       "      <td>0.247237</td>\n",
       "      <td>-0.106984</td>\n",
       "      <td>0.729727</td>\n",
       "      <td>-0.161666</td>\n",
       "      <td>0.312561</td>\n",
       "      <td>-0.414116</td>\n",
       "      <td>1.071126</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.419117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_amount        V1        V2       V3        V4       V5       V6       V7  \\\n",
       "0  0.496764 -0.260648 -0.469648 2.496266 -0.083724 0.129681 0.732898 0.519014   \n",
       "1 -0.458942  0.985100 -0.356045 0.558056 -0.429654 0.277140 0.428605 0.406466   \n",
       "2 -0.794279 -0.260272 -0.949385 1.728538 -0.457986 0.074062 1.419481 0.743511   \n",
       "3 -0.554667 -0.152152 -0.508959 1.746840 -1.090178 0.249486 1.143312 0.518269   \n",
       "4  0.187692 -0.206820 -0.165280 1.527053 -0.448293 0.106125 0.530549 0.658849   \n",
       "\n",
       "         V8        V9      V10       V11      V12       V13      V14  \\\n",
       "0 -0.130006  0.727159 0.637735 -0.987020 0.293438 -0.941386 0.549020   \n",
       "1 -0.133118  0.347452 0.529808  0.140107 1.564246  0.574074 0.627719   \n",
       "2 -0.095576 -0.261297 0.690708 -0.272985 0.659201  0.805173 0.616874   \n",
       "3 -0.065130 -0.205698 0.575231 -0.752581 0.737483  0.592994 0.559535   \n",
       "4 -0.212660  1.049921 0.968046 -1.203171 1.029577  1.439310 0.241454   \n",
       "\n",
       "        V15       V16      V17      V18       V19       V20       V21  \\\n",
       "0  1.804879  0.215598 0.512307 0.333644  0.124270  0.091202 -0.110552   \n",
       "1  0.706121  0.789188 0.403810 0.201799 -0.340687 -0.233984 -0.194936   \n",
       "2  3.069025 -0.577514 0.886526 0.239442 -2.366079  0.361652 -0.005020   \n",
       "3 -0.697664 -0.030669 0.242629 2.178616 -1.345060 -0.378223 -0.146927   \n",
       "4  0.153008  0.224538 0.366466 0.291782  0.445317  0.247237 -0.106984   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  Class  \n",
       "0  0.217606 -0.134794  0.165959  0.126280 -0.434824 -0.081230 -0.151045      0  \n",
       "1 -0.605761  0.079469 -0.577395  0.190090  0.296503 -0.248052 -0.064512      0  \n",
       "2  0.702906  0.945045 -1.154666 -0.605564 -0.312895 -0.300258 -0.244718      0  \n",
       "3 -0.038212 -0.214048 -1.893131  1.003963 -0.515950 -0.165316  0.048424      0  \n",
       "4  0.729727 -0.161666  0.312561 -0.414116  1.071126  0.023712  0.419117      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719f1085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting Training and testing data\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8aabbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9150af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f67bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [ 57020  57021  57022 ... 568627 568628 568629] Test: [     0      1      2 ... 341175 341176 341177]\n",
      "Train: [     0      1      2 ... 568627 568628 568629] Test: [ 57020  57021  57022 ... 398038 398039 398040]\n",
      "Train: [     0      1      2 ... 568627 568628 568629] Test: [113967 113968 113969 ... 454901 454902 454903]\n",
      "Train: [     0      1      2 ... 568627 568628 568629] Test: [170949 170950 170951 ... 511764 511765 511766]\n",
      "Train: [     0      1      2 ... 511764 511765 511766] Test: [227869 227870 227871 ... 568627 568628 568629]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Label Distributions: \n",
      "\n",
      "[0.5 0.5]\n",
      "[0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Check the Distribution of the labels\n",
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = original_Xtest.values\n",
    "original_ytrain = original_ytrain.values\n",
    "original_ytest = original_ytest.values\n",
    "\n",
    "# Check to see if the distribution of the test and train labels is similar.\n",
    "train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\n",
    "test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n",
    "print('-' * 100)\n",
    "\n",
    "print('Label Distributions: \\n')\n",
    "print(train_counts_label/ len(original_ytrain))\n",
    "print(test_counts_label/ len(original_ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec72731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd12aff7",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "by including tweaking for max_depth and n_estimators alongside learning_rate, we'll set up a nested loop to iterate over combinations of these parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "551d1576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3e820c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.01, Depth: 3, Estimators: 20 2.4953768253326416\n",
      "LR: 0.01, Depth: 3, Estimators: 50 3.1014468669891357\n",
      "LR: 0.01, Depth: 3, Estimators: 100 4.545229911804199\n",
      "LR: 0.01, Depth: 3, Estimators: 200 10.813835144042969\n",
      "LR: 0.01, Depth: 3, Estimators: 500 17.317631483078003\n",
      "LR: 0.01, Depth: 3, Estimators: 1000 33.41537570953369\n",
      "LR: 0.01, Depth: 6, Estimators: 20 2.6912264823913574\n",
      "LR: 0.01, Depth: 6, Estimators: 50 7.183120012283325\n",
      "LR: 0.01, Depth: 6, Estimators: 100 5.082107782363892\n",
      "LR: 0.01, Depth: 6, Estimators: 200 13.874131202697754\n",
      "LR: 0.01, Depth: 6, Estimators: 500 32.64604997634888\n",
      "LR: 0.01, Depth: 6, Estimators: 1000 49.293800592422485\n",
      "LR: 0.01, Depth: 9, Estimators: 20 3.430760145187378\n",
      "LR: 0.01, Depth: 9, Estimators: 50 9.819521188735962\n",
      "LR: 0.01, Depth: 9, Estimators: 100 7.832666397094727\n",
      "LR: 0.01, Depth: 9, Estimators: 200 16.661863803863525\n",
      "LR: 0.01, Depth: 9, Estimators: 500 43.02814531326294\n",
      "LR: 0.01, Depth: 9, Estimators: 1000 67.05780363082886\n",
      "LR: 0.1, Depth: 3, Estimators: 20 2.7323975563049316\n",
      "LR: 0.1, Depth: 3, Estimators: 50 4.964929819107056\n",
      "LR: 0.1, Depth: 3, Estimators: 100 3.9670398235321045\n",
      "LR: 0.1, Depth: 3, Estimators: 200 6.1000823974609375\n",
      "LR: 0.1, Depth: 3, Estimators: 500 15.42361855506897\n",
      "LR: 0.1, Depth: 3, Estimators: 1000 32.137286901474\n",
      "LR: 0.1, Depth: 6, Estimators: 20 5.358241558074951\n",
      "LR: 0.1, Depth: 6, Estimators: 50 3.417424201965332\n",
      "LR: 0.1, Depth: 6, Estimators: 100 4.932531833648682\n",
      "LR: 0.1, Depth: 6, Estimators: 200 13.185596942901611\n",
      "LR: 0.1, Depth: 6, Estimators: 500 22.714320182800293\n",
      "LR: 0.1, Depth: 6, Estimators: 1000 43.047362089157104\n",
      "LR: 0.1, Depth: 9, Estimators: 20 3.2814488410949707\n",
      "LR: 0.1, Depth: 9, Estimators: 50 8.322670698165894\n",
      "LR: 0.1, Depth: 9, Estimators: 100 6.6666035652160645\n",
      "LR: 0.1, Depth: 9, Estimators: 200 15.822890520095825\n",
      "LR: 0.1, Depth: 9, Estimators: 500 29.59739875793457\n",
      "LR: 0.1, Depth: 9, Estimators: 1000 48.85327124595642\n",
      "LR: 0.3, Depth: 3, Estimators: 20 2.296696901321411\n",
      "LR: 0.3, Depth: 3, Estimators: 50 5.6650002002716064\n",
      "LR: 0.3, Depth: 3, Estimators: 100 3.883847951889038\n",
      "LR: 0.3, Depth: 3, Estimators: 200 6.242406606674194\n",
      "LR: 0.3, Depth: 3, Estimators: 500 17.530032873153687\n",
      "LR: 0.3, Depth: 3, Estimators: 1000 30.129831075668335\n",
      "LR: 0.3, Depth: 6, Estimators: 20 5.5426225662231445\n",
      "LR: 0.3, Depth: 6, Estimators: 50 3.6019439697265625\n",
      "LR: 0.3, Depth: 6, Estimators: 100 5.509409427642822\n",
      "LR: 0.3, Depth: 6, Estimators: 200 13.704379320144653\n",
      "LR: 0.3, Depth: 6, Estimators: 500 22.0037944316864\n",
      "LR: 0.3, Depth: 6, Estimators: 1000 35.35772180557251\n",
      "LR: 0.3, Depth: 9, Estimators: 20 3.162052869796753\n",
      "LR: 0.3, Depth: 9, Estimators: 50 4.256088018417358\n",
      "LR: 0.3, Depth: 9, Estimators: 100 9.237278938293457\n",
      "LR: 0.3, Depth: 9, Estimators: 200 9.447994709014893\n",
      "LR: 0.3, Depth: 9, Estimators: 500 27.067080974578857\n",
      "LR: 0.3, Depth: 9, Estimators: 1000 37.90961265563965\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# Define ranges for the parameters to test\n",
    "learning_rates = [0.01, 0.1, 0.3]\n",
    "max_depths = [3, 6, 9]\n",
    "n_estimators = [20, 50, 100, 200, 500, 1000]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over the combinations of learning_rates, max_depths, and n_estimators\n",
    "for lr in learning_rates:\n",
    "    for depth in max_depths:\n",
    "        for n_est in n_estimators:\n",
    "            start_time = time.time()  # Start timing\n",
    "            \n",
    "            # Instantiate and fit the XGBoost classifier\n",
    "            xgb_classifier = xgb.XGBClassifier(learning_rate=lr, max_depth=depth, n_estimators=n_est,\n",
    "                                               use_label_encoder=False, eval_metric='logloss')\n",
    "            xgb_classifier.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict and evaluate on training data\n",
    "            y_train_pred = xgb_classifier.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "            train_f1 = f1_score(y_train, y_train_pred)\n",
    "            train_recall = recall_score(y_train, y_train_pred)\n",
    "            train_precision = precision_score(y_train, y_train_pred)\n",
    "            \n",
    "            # Predict and evaluate on testing data\n",
    "            y_test_pred = xgb_classifier.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            test_f1 = f1_score(y_test, y_test_pred)\n",
    "            test_recall = recall_score(y_test, y_test_pred)\n",
    "            test_precision = precision_score(y_test, y_test_pred)\n",
    "            \n",
    "            # Calculate elapsed time\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            \n",
    "            # Append training and testing results separately, including parameter values and execution time\n",
    "            params = f'LR: {lr}, Depth: {depth}, Estimators: {n_est}'\n",
    "            \n",
    "            print(params, elapsed_time)\n",
    "            \n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Training',\n",
    "                'Accuracy': train_accuracy,\n",
    "                'F1 Score': train_f1,\n",
    "                'Recall': train_recall,\n",
    "                'Precision': train_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Testing',\n",
    "                'Accuracy': test_accuracy,\n",
    "                'F1 Score': test_f1,\n",
    "                'Recall': test_recall,\n",
    "                'Precision': test_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4af2cb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Data Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Execution Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 20</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.948198</td>\n",
       "      <td>0.947371</td>\n",
       "      <td>0.932959</td>\n",
       "      <td>0.962236</td>\n",
       "      <td>2.495377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 20</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.947620</td>\n",
       "      <td>0.946941</td>\n",
       "      <td>0.932972</td>\n",
       "      <td>0.961335</td>\n",
       "      <td>2.495377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 50</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.953933</td>\n",
       "      <td>0.952658</td>\n",
       "      <td>0.927452</td>\n",
       "      <td>0.979272</td>\n",
       "      <td>3.101447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 50</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.953687</td>\n",
       "      <td>0.952531</td>\n",
       "      <td>0.927496</td>\n",
       "      <td>0.978956</td>\n",
       "      <td>3.101447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 100</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.951629</td>\n",
       "      <td>0.949752</td>\n",
       "      <td>0.914718</td>\n",
       "      <td>0.987576</td>\n",
       "      <td>4.545230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Parameters Data Split  Accuracy  F1 Score  \\\n",
       "0   LR: 0.01, Depth: 3, Estimators: 20   Training  0.948198  0.947371   \n",
       "1   LR: 0.01, Depth: 3, Estimators: 20    Testing  0.947620  0.946941   \n",
       "2   LR: 0.01, Depth: 3, Estimators: 50   Training  0.953933  0.952658   \n",
       "3   LR: 0.01, Depth: 3, Estimators: 50    Testing  0.953687  0.952531   \n",
       "4  LR: 0.01, Depth: 3, Estimators: 100   Training  0.951629  0.949752   \n",
       "\n",
       "    Recall  Precision  Execution Time (s)  \n",
       "0 0.932959   0.962236            2.495377  \n",
       "1 0.932972   0.961335            2.495377  \n",
       "2 0.927452   0.979272            3.101447  \n",
       "3 0.927496   0.978956            3.101447  \n",
       "4 0.914718   0.987576            4.545230  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdccbef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('data2_results/XGBoost_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f285ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eac49d95",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "To experiment with the AdaBoost algorithm and tweak its parameters, we can adjust the number of estimators (n_estimators) and the learning rate (learning_rate). These are two key parameters for AdaBoost that influence the performance and complexity of the resulting model. The n_estimators parameter controls the number of sequential models to be added to correct the errors of the previous models, while learning_rate scales the contribution of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5611c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 10, LR: 0.01 38.72339916229248\n",
      "Estimators: 10, LR: 0.1 38.582165002822876\n",
      "Estimators: 10, LR: 0.5 38.85813236236572\n",
      "Estimators: 10, LR: 1 38.44630789756775\n",
      "Estimators: 25, LR: 0.01 95.35388898849487\n",
      "Estimators: 25, LR: 0.1 96.85238933563232\n",
      "Estimators: 25, LR: 0.5 97.05669522285461\n",
      "Estimators: 25, LR: 1 95.1578369140625\n",
      "Estimators: 50, LR: 0.01 190.02480030059814\n",
      "Estimators: 50, LR: 0.1 189.15585112571716\n",
      "Estimators: 50, LR: 0.5 189.37187027931213\n",
      "Estimators: 50, LR: 1 189.97536420822144\n",
      "Estimators: 100, LR: 0.01 381.32956624031067\n",
      "Estimators: 100, LR: 0.1 381.91789197921753\n",
      "Estimators: 100, LR: 0.5 380.7166266441345\n",
      "Estimators: 100, LR: 1 379.6542992591858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# Define ranges for the parameters to test\n",
    "n_estimators_list = [10, 25, 50, 100] #, 500, 1000, 5000] #Too slow to run all. At 1000 took 4 hours and crashed.\n",
    "learning_rates_list = [0.01, 0.1, 0.5, 1] #, 2]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over the combinations of n_estimators and learning_rates\n",
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rates_list:\n",
    "        start_time = time.time()  # Start timing\n",
    "        \n",
    "        # Instantiate and fit the AdaBoost classifier\n",
    "        ada_classifier = AdaBoostClassifier(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "        ada_classifier.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and evaluate on training data\n",
    "        y_train_pred = ada_classifier.predict(X_train)\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        train_f1 = f1_score(y_train, y_train_pred)\n",
    "        train_recall = recall_score(y_train, y_train_pred)\n",
    "        train_precision = precision_score(y_train, y_train_pred)\n",
    "        \n",
    "        # Predict and evaluate on testing data\n",
    "        y_test_pred = ada_classifier.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        test_f1 = f1_score(y_test, y_test_pred)\n",
    "        test_recall = recall_score(y_test, y_test_pred)\n",
    "        test_precision = precision_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        # Append training and testing results separately, including parameter values and execution time\n",
    "        params = f'Estimators: {n_estimators}, LR: {learning_rate}'\n",
    "        print(params, elapsed_time)\n",
    "        results.append({\n",
    "            'Parameters': params,\n",
    "            'Data Split': 'Training',\n",
    "            'Accuracy': train_accuracy,\n",
    "            'F1 Score': train_f1,\n",
    "            'Recall': train_recall,\n",
    "            'Precision': train_precision,\n",
    "            'Execution Time (s)': elapsed_time\n",
    "        })\n",
    "        results.append({\n",
    "            'Parameters': params,\n",
    "            'Data Split': 'Testing',\n",
    "            'Accuracy': test_accuracy,\n",
    "            'F1 Score': test_f1,\n",
    "            'Recall': test_recall,\n",
    "            'Precision': test_precision,\n",
    "            'Execution Time (s)': elapsed_time\n",
    "        })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2116cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Data Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Execution Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estimators: 10, LR: 0.01</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.931711</td>\n",
       "      <td>0.928612</td>\n",
       "      <td>0.888748</td>\n",
       "      <td>0.972221</td>\n",
       "      <td>38.723399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Estimators: 10, LR: 0.01</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.932162</td>\n",
       "      <td>0.929277</td>\n",
       "      <td>0.889603</td>\n",
       "      <td>0.972655</td>\n",
       "      <td>38.723399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Estimators: 10, LR: 0.1</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.937917</td>\n",
       "      <td>0.935077</td>\n",
       "      <td>0.894629</td>\n",
       "      <td>0.979357</td>\n",
       "      <td>38.582165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estimators: 10, LR: 0.1</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.938704</td>\n",
       "      <td>0.936100</td>\n",
       "      <td>0.896184</td>\n",
       "      <td>0.979738</td>\n",
       "      <td>38.582165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estimators: 10, LR: 0.5</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.948706</td>\n",
       "      <td>0.947274</td>\n",
       "      <td>0.922015</td>\n",
       "      <td>0.973956</td>\n",
       "      <td>38.858132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Parameters Data Split  Accuracy  F1 Score   Recall  \\\n",
       "0  Estimators: 10, LR: 0.01   Training  0.931711  0.928612 0.888748   \n",
       "1  Estimators: 10, LR: 0.01    Testing  0.932162  0.929277 0.889603   \n",
       "2   Estimators: 10, LR: 0.1   Training  0.937917  0.935077 0.894629   \n",
       "3   Estimators: 10, LR: 0.1    Testing  0.938704  0.936100 0.896184   \n",
       "4   Estimators: 10, LR: 0.5   Training  0.948706  0.947274 0.922015   \n",
       "\n",
       "   Precision  Execution Time (s)  \n",
       "0   0.972221           38.723399  \n",
       "1   0.972655           38.723399  \n",
       "2   0.979357           38.582165  \n",
       "3   0.979738           38.582165  \n",
       "4   0.973956           38.858132  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_excel('data2_results/AdaBoost_results.xlsx', index=False)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b052500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "724b3b8e",
   "metadata": {},
   "source": [
    "## AdaBoost with Decision Tree clacifier\n",
    "\n",
    "AdaBoost, as implemented in scikit-learn (AdaBoostClassifier), doesn't directly accept a max_depth parameter because AdaBoost can be used with various types of base estimators, not just decision trees. This is a frequent way of using AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0101ef94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 10, LR: 0.01, Depth: 3 102.31569004058838\n",
      "Estimators: 10, LR: 0.01, Depth: 5 166.09842157363892\n",
      "Estimators: 10, LR: 0.01, Depth: 7 233.21162915229797\n",
      "Estimators: 10, LR: 0.1, Depth: 3 104.77864599227905\n",
      "Estimators: 10, LR: 0.1, Depth: 5 173.04592084884644\n",
      "Estimators: 10, LR: 0.1, Depth: 7 233.71685528755188\n",
      "Estimators: 10, LR: 0.3, Depth: 3 102.45896935462952\n",
      "Estimators: 10, LR: 0.3, Depth: 5 167.55185723304749\n",
      "Estimators: 10, LR: 0.3, Depth: 7 227.46368050575256\n",
      "Estimators: 25, LR: 0.01, Depth: 3 261.5536754131317\n",
      "Estimators: 25, LR: 0.01, Depth: 5 412.54430961608887\n",
      "Estimators: 25, LR: 0.01, Depth: 7 579.35755443573\n",
      "Estimators: 25, LR: 0.1, Depth: 3 257.77327489852905\n",
      "Estimators: 25, LR: 0.1, Depth: 5 414.39040422439575\n",
      "Estimators: 25, LR: 0.1, Depth: 7 569.3035671710968\n",
      "Estimators: 25, LR: 0.3, Depth: 3 267.8144872188568\n",
      "Estimators: 25, LR: 0.3, Depth: 5 422.5403587818146\n",
      "Estimators: 25, LR: 0.3, Depth: 7 578.2721581459045\n",
      "Estimators: 50, LR: 0.01, Depth: 3 517.151166677475\n",
      "Estimators: 50, LR: 0.01, Depth: 5 838.7949738502502\n",
      "Estimators: 50, LR: 0.01, Depth: 7 1149.7049360275269\n",
      "Estimators: 50, LR: 0.1, Depth: 3 524.3943321704865\n",
      "Estimators: 50, LR: 0.1, Depth: 5 845.9112133979797\n",
      "Estimators: 50, LR: 0.1, Depth: 7 1142.2591333389282\n",
      "Estimators: 50, LR: 0.3, Depth: 3 546.0937762260437\n",
      "Estimators: 50, LR: 0.3, Depth: 5 858.8886728286743\n",
      "Estimators: 50, LR: 0.3, Depth: 7 1131.3884377479553\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# Define ranges for the parameters to test\n",
    "n_estimators_list = [10, 25, 50] #, 500, 1000, 5000]\n",
    "learning_rates_list = [0.01, 0.1, 0.3]\n",
    "max_depths = [3, 5, 7]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over the combinations of n_estimators, learning_rates, and max_depths\n",
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rates_list:\n",
    "        for max_depth in max_depths:\n",
    "            start_time = time.time()  # Start timing\n",
    "            \n",
    "            # Create a DecisionTreeClassifier with the specified max_depth\n",
    "            base_estimator = DecisionTreeClassifier(max_depth=max_depth)\n",
    "            \n",
    "            # Instantiate and fit the AdaBoost classifier with the DecisionTree base estimator\n",
    "            ada_classifier = AdaBoostClassifier(\n",
    "                base_estimator=base_estimator,\n",
    "                n_estimators=n_estimators,\n",
    "                learning_rate=learning_rate\n",
    "            )\n",
    "            ada_classifier.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict and evaluate on training data\n",
    "            y_train_pred = ada_classifier.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "            train_f1 = f1_score(y_train, y_train_pred)\n",
    "            train_recall = recall_score(y_train, y_train_pred)\n",
    "            train_precision = precision_score(y_train, y_train_pred)\n",
    "            \n",
    "            # Predict and evaluate on testing data\n",
    "            y_test_pred = ada_classifier.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            test_f1 = f1_score(y_test, y_test_pred)\n",
    "            test_recall = recall_score(y_test, y_test_pred)\n",
    "            test_precision = precision_score(y_test, y_test_pred)\n",
    "            \n",
    "            # Calculate elapsed time\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            \n",
    "            # Append training and testing results separately, including parameter values and execution time\n",
    "            params = f'Estimators: {n_estimators}, LR: {learning_rate}, Depth: {max_depth}'\n",
    "            print(params, elapsed_time)\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Training',\n",
    "                'Accuracy': train_accuracy,\n",
    "                'F1 Score': train_f1,\n",
    "                'Recall': train_recall,\n",
    "                'Precision': train_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Testing',\n",
    "                'Accuracy': test_accuracy,\n",
    "                'F1 Score': test_f1,\n",
    "                'Recall': test_recall,\n",
    "                'Precision': test_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fe6710d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Data Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Execution Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estimators: 10, LR: 0.01, Depth: 3</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.947061</td>\n",
       "      <td>0.945133</td>\n",
       "      <td>0.912360</td>\n",
       "      <td>0.980347</td>\n",
       "      <td>102.315690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Estimators: 10, LR: 0.01, Depth: 3</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.947980</td>\n",
       "      <td>0.946304</td>\n",
       "      <td>0.914947</td>\n",
       "      <td>0.979887</td>\n",
       "      <td>102.315690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Estimators: 10, LR: 0.01, Depth: 5</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.965819</td>\n",
       "      <td>0.965338</td>\n",
       "      <td>0.952397</td>\n",
       "      <td>0.978634</td>\n",
       "      <td>166.098422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estimators: 10, LR: 0.01, Depth: 5</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.965329</td>\n",
       "      <td>0.964961</td>\n",
       "      <td>0.952928</td>\n",
       "      <td>0.977302</td>\n",
       "      <td>166.098422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estimators: 10, LR: 0.01, Depth: 7</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.977780</td>\n",
       "      <td>0.977484</td>\n",
       "      <td>0.965136</td>\n",
       "      <td>0.990153</td>\n",
       "      <td>233.211629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Parameters Data Split  Accuracy  F1 Score   Recall  \\\n",
       "0  Estimators: 10, LR: 0.01, Depth: 3   Training  0.947061  0.945133 0.912360   \n",
       "1  Estimators: 10, LR: 0.01, Depth: 3    Testing  0.947980  0.946304 0.914947   \n",
       "2  Estimators: 10, LR: 0.01, Depth: 5   Training  0.965819  0.965338 0.952397   \n",
       "3  Estimators: 10, LR: 0.01, Depth: 5    Testing  0.965329  0.964961 0.952928   \n",
       "4  Estimators: 10, LR: 0.01, Depth: 7   Training  0.977780  0.977484 0.965136   \n",
       "\n",
       "   Precision  Execution Time (s)  \n",
       "0   0.980347          102.315690  \n",
       "1   0.979887          102.315690  \n",
       "2   0.978634          166.098422  \n",
       "3   0.977302          166.098422  \n",
       "4   0.990153          233.211629  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_excel('data2_results/AdaBoostDT_results.xlsx', index=False)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693661be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2746e8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9524046",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machine\n",
    "\n",
    "To perform a similar parameter tweaking experiment with a Gradient Boosting Machine (GBM) using scikit-learn's GradientBoostingClassifier, we can iterate over combinations of n_estimators, learning_rate, and max_depth. These parameters are analogous to those adjusted in the AdaBoost and XGBoost, serving similar purposes:\n",
    "\n",
    "n_estimators: controls the number of sequential trees to be modeled.\n",
    "learning_rate: scales the contribution of each tree.\n",
    "max_depth: sets the maximum depth of each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b272ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 10, LR: 0.01, Depth: 3 548.9556698799133\n",
      "Estimators: 10, LR: 0.01, Depth: 5 633.0351781845093\n",
      "Estimators: 10, LR: 0.01, Depth: 7 760.003781080246\n",
      "Estimators: 10, LR: 0.1, Depth: 3 221.40730714797974\n",
      "Estimators: 10, LR: 0.1, Depth: 5 349.8702447414398\n",
      "Estimators: 10, LR: 0.1, Depth: 7 564.2601475715637\n",
      "Estimators: 10, LR: 0.3, Depth: 3 339.71960520744324\n",
      "Estimators: 10, LR: 0.3, Depth: 5 462.6554033756256\n",
      "Estimators: 10, LR: 0.3, Depth: 7 454.9595196247101\n",
      "Estimators: 20, LR: 0.01, Depth: 3 407.6106336116791\n",
      "Estimators: 20, LR: 0.01, Depth: 5 680.3393642902374\n",
      "Estimators: 20, LR: 0.01, Depth: 7 2105.3441553115845\n",
      "Estimators: 20, LR: 0.1, Depth: 3 400.140291929245\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# Define ranges for the parameters to test\n",
    "n_estimators_list = [10, 20, 50]\n",
    "learning_rates_list = [0.01, 0.1, 0.3]\n",
    "max_depths = [3, 5, 7]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over the combinations of n_estimators, learning_rates, and max_depths\n",
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rates_list:\n",
    "        for max_depth in max_depths:\n",
    "            start_time = time.time()  # Start timing\n",
    "            \n",
    "            # Instantiate and fit the GradientBoostingClassifier\n",
    "            gbm_classifier = GradientBoostingClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                learning_rate=learning_rate,\n",
    "                max_depth=max_depth\n",
    "            )\n",
    "            gbm_classifier.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict and evaluate on training data\n",
    "            y_train_pred = gbm_classifier.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "            train_f1 = f1_score(y_train, y_train_pred)\n",
    "            train_recall = recall_score(y_train, y_train_pred)\n",
    "            train_precision = precision_score(y_train, y_train_pred)\n",
    "            \n",
    "            # Predict and evaluate on testing data\n",
    "            y_test_pred = gbm_classifier.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            test_f1 = f1_score(y_test, y_test_pred)\n",
    "            test_recall = recall_score(y_test, y_test_pred)\n",
    "            test_precision = precision_score(y_test, y_test_pred)\n",
    "            \n",
    "            # Calculate elapsed time\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            \n",
    "            # Append training and testing results separately, including parameter values and execution time\n",
    "            params = f'Estimators: {n_estimators}, LR: {learning_rate}, Depth: {max_depth}'\n",
    "            print(params, elapsed_time)\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Training',\n",
    "                'Accuracy': train_accuracy,\n",
    "                'F1 Score': train_f1,\n",
    "                'Recall': train_recall,\n",
    "                'Precision': train_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Testing',\n",
    "                'Accuracy': test_accuracy,\n",
    "                'F1 Score': test_f1,\n",
    "                'Recall': test_recall,\n",
    "                'Precision': test_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48458340",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('data2_results/GBM_results.xlsx', index=False)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9292b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79f2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb42b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7e990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c887899e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a8d4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da7830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586468f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638a95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76116dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad37cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086b639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ceda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af484487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6217910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
