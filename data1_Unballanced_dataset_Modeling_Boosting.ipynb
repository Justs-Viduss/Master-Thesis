{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b49190e",
   "metadata": {},
   "source": [
    "# Unballanced dataset model implementation\n",
    "\n",
    "    \n",
    "### Boosting alghoritms: \n",
    "    XGBoost\n",
    "    AdaBoost\n",
    "    Gradient Boosting Machine\n",
    "    Optimized light gradient boosting \n",
    "    CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb9794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2417b810",
   "metadata": {},
   "source": [
    "## Unballanced dataset Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7304c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors  \n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867e6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/data1_unballanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1de8421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_amount</th>\n",
       "      <th>s_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.783274</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.983721</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.670579</td>\n",
       "      <td>-0.994960</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_amount    s_time        V1        V2       V3        V4        V5  \\\n",
       "0  1.783274 -0.994983 -1.359807 -0.072781 2.536347  1.378155 -0.338321   \n",
       "1 -0.269825 -0.994983  1.191857  0.266151 0.166480  0.448154  0.060018   \n",
       "2  4.983721 -0.994972 -1.358354 -1.340163 1.773209  0.379780 -0.503198   \n",
       "3  1.418291 -0.994972 -0.966272 -0.185226 1.792993 -0.863291 -0.010309   \n",
       "4  0.670579 -0.994960 -1.158233  0.877737 1.548718  0.403034 -0.407193   \n",
       "\n",
       "         V6        V7        V8        V9       V10       V11       V12  \\\n",
       "0  0.462388  0.239599  0.098698  0.363787  0.090794 -0.551600 -0.617801   \n",
       "1 -0.082361 -0.078803  0.085102 -0.255425 -0.166974  1.612727  1.065235   \n",
       "2  1.800499  0.791461  0.247676 -1.514654  0.207643  0.624501  0.066084   \n",
       "3  1.247203  0.237609  0.377436 -1.387024 -0.054952 -0.226487  0.178228   \n",
       "4  0.095921  0.592941 -0.270533  0.817739  0.753074 -0.822843  0.538196   \n",
       "\n",
       "        V13       V14       V15       V16       V17       V18       V19  \\\n",
       "0 -0.991390 -0.311169  1.468177 -0.470401  0.207971  0.025791  0.403993   \n",
       "1  0.489095 -0.143772  0.635558  0.463917 -0.114805 -0.183361 -0.145783   \n",
       "2  0.717293 -0.165946  2.345865 -2.890083  1.109969 -0.121359 -2.261857   \n",
       "3  0.507757 -0.287924 -0.631418 -1.059647 -0.684093  1.965775 -1.232622   \n",
       "4  1.345852 -1.119670  0.175121 -0.451449 -0.237033 -0.038195  0.803487   \n",
       "\n",
       "        V20       V21       V22       V23       V24       V25       V26  \\\n",
       "0  0.251412 -0.018307  0.277838 -0.110474  0.066928  0.128539 -0.189115   \n",
       "1 -0.069083 -0.225775 -0.638672  0.101288 -0.339846  0.167170  0.125895   \n",
       "2  0.524980  0.247998  0.771679  0.909412 -0.689281 -0.327642 -0.139097   \n",
       "3 -0.208038 -0.108300  0.005274 -0.190321 -1.175575  0.647376 -0.221929   \n",
       "4  0.408542 -0.009431  0.798278 -0.137458  0.141267 -0.206010  0.502292   \n",
       "\n",
       "        V27       V28  Class  \n",
       "0  0.133558 -0.021053      0  \n",
       "1 -0.008983  0.014724      0  \n",
       "2 -0.055353 -0.059752      0  \n",
       "3  0.062723  0.061458      0  \n",
       "4  0.219422  0.215153      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "719f1085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting Training and testing data\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8aabbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9150af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f67bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [ 30473  30496  31002 ... 284804 284805 284806] Test: [    0     1     2 ... 57017 57018 57019]\n",
      "Train: [     0      1      2 ... 284804 284805 284806] Test: [ 30473  30496  31002 ... 113964 113965 113966]\n",
      "Train: [     0      1      2 ... 284804 284805 284806] Test: [ 81609  82400  83053 ... 170946 170947 170948]\n",
      "Train: [     0      1      2 ... 284804 284805 284806] Test: [150654 150660 150661 ... 227866 227867 227868]\n",
      "Train: [     0      1      2 ... 227866 227867 227868] Test: [212516 212644 213092 ... 284804 284805 284806]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Label Distributions: \n",
      "\n",
      "[0.99827076 0.00172924]\n",
      "[0.99827952 0.00172048]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Check the Distribution of the labels\n",
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = original_Xtest.values\n",
    "original_ytrain = original_ytrain.values\n",
    "original_ytest = original_ytest.values\n",
    "\n",
    "# Check to see if the distribution of the test and train labels is similar.\n",
    "train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\n",
    "test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n",
    "print('-' * 100)\n",
    "\n",
    "print('Label Distributions: \\n')\n",
    "print(train_counts_label/ len(original_ytrain))\n",
    "print(test_counts_label/ len(original_ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fec72731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd12aff7",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "by including tweaking for max_depth and n_estimators alongside learning_rate, we'll set up a nested loop to iterate over combinations of these parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "551d1576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3e820c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.01, Depth: 3, Estimators: 20 0.9533159732818604\n",
      "LR: 0.01, Depth: 3, Estimators: 50 1.0730090141296387\n",
      "LR: 0.01, Depth: 3, Estimators: 100 1.5861845016479492\n",
      "LR: 0.01, Depth: 3, Estimators: 200 2.5883305072784424\n",
      "LR: 0.01, Depth: 3, Estimators: 500 5.996670961380005\n",
      "LR: 0.01, Depth: 3, Estimators: 1000 12.715234518051147\n",
      "LR: 0.01, Depth: 6, Estimators: 20 0.8032400608062744\n",
      "LR: 0.01, Depth: 6, Estimators: 50 1.138197660446167\n",
      "LR: 0.01, Depth: 6, Estimators: 100 1.787552833557129\n",
      "LR: 0.01, Depth: 6, Estimators: 200 2.9922940731048584\n",
      "LR: 0.01, Depth: 6, Estimators: 500 8.523376226425171\n",
      "LR: 0.01, Depth: 6, Estimators: 1000 19.96651864051819\n",
      "LR: 0.01, Depth: 9, Estimators: 20 1.0824594497680664\n",
      "LR: 0.01, Depth: 9, Estimators: 50 1.5159637928009033\n",
      "LR: 0.01, Depth: 9, Estimators: 100 1.8650438785552979\n",
      "LR: 0.01, Depth: 9, Estimators: 200 3.9746532440185547\n",
      "LR: 0.01, Depth: 9, Estimators: 500 9.209301233291626\n",
      "LR: 0.01, Depth: 9, Estimators: 1000 21.599347591400146\n",
      "LR: 0.1, Depth: 3, Estimators: 20 0.9837179183959961\n",
      "LR: 0.1, Depth: 3, Estimators: 50 1.3810980319976807\n",
      "LR: 0.1, Depth: 3, Estimators: 100 2.2000749111175537\n",
      "LR: 0.1, Depth: 3, Estimators: 200 3.414525270462036\n",
      "LR: 0.1, Depth: 3, Estimators: 500 7.794652223587036\n",
      "LR: 0.1, Depth: 3, Estimators: 1000 14.932668924331665\n",
      "LR: 0.1, Depth: 6, Estimators: 20 0.9852468967437744\n",
      "LR: 0.1, Depth: 6, Estimators: 50 1.62457275390625\n",
      "LR: 0.1, Depth: 6, Estimators: 100 2.775268077850342\n",
      "LR: 0.1, Depth: 6, Estimators: 200 5.5262839794158936\n",
      "LR: 0.1, Depth: 6, Estimators: 500 11.775660514831543\n",
      "LR: 0.1, Depth: 6, Estimators: 1000 18.853639364242554\n",
      "LR: 0.1, Depth: 9, Estimators: 20 0.9957051277160645\n",
      "LR: 0.1, Depth: 9, Estimators: 50 1.5580642223358154\n",
      "LR: 0.1, Depth: 9, Estimators: 100 3.645599842071533\n",
      "LR: 0.1, Depth: 9, Estimators: 200 6.651098966598511\n",
      "LR: 0.1, Depth: 9, Estimators: 500 14.855737447738647\n",
      "LR: 0.1, Depth: 9, Estimators: 1000 24.156384706497192\n",
      "LR: 0.3, Depth: 3, Estimators: 20 1.020684003829956\n",
      "LR: 0.3, Depth: 3, Estimators: 50 2.0104639530181885\n",
      "LR: 0.3, Depth: 3, Estimators: 100 3.3602957725524902\n",
      "LR: 0.3, Depth: 3, Estimators: 200 4.320690631866455\n",
      "LR: 0.3, Depth: 3, Estimators: 500 9.77170467376709\n",
      "LR: 0.3, Depth: 3, Estimators: 1000 20.976186990737915\n",
      "LR: 0.3, Depth: 6, Estimators: 20 1.9063827991485596\n",
      "LR: 0.3, Depth: 6, Estimators: 50 2.8302719593048096\n",
      "LR: 0.3, Depth: 6, Estimators: 100 4.146519422531128\n",
      "LR: 0.3, Depth: 6, Estimators: 200 7.377300500869751\n",
      "LR: 0.3, Depth: 6, Estimators: 500 14.010305404663086\n",
      "LR: 0.3, Depth: 6, Estimators: 1000 24.73545002937317\n",
      "LR: 0.3, Depth: 9, Estimators: 20 1.7155821323394775\n",
      "LR: 0.3, Depth: 9, Estimators: 50 2.6113040447235107\n",
      "LR: 0.3, Depth: 9, Estimators: 100 4.242041349411011\n",
      "LR: 0.3, Depth: 9, Estimators: 200 7.218907117843628\n",
      "LR: 0.3, Depth: 9, Estimators: 500 14.164377927780151\n",
      "LR: 0.3, Depth: 9, Estimators: 1000 20.13795566558838\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# Define ranges for the parameters to test\n",
    "learning_rates = [0.01, 0.1, 0.3]\n",
    "max_depths = [3, 6, 9]\n",
    "n_estimators = [20, 50, 100, 200, 500, 1000]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over the combinations of learning_rates, max_depths, and n_estimators\n",
    "for lr in learning_rates:\n",
    "    for depth in max_depths:\n",
    "        for n_est in n_estimators:\n",
    "            start_time = time.time()  # Start timing\n",
    "            \n",
    "            # Instantiate and fit the XGBoost classifier\n",
    "            xgb_classifier = xgb.XGBClassifier(learning_rate=lr, max_depth=depth, n_estimators=n_est,\n",
    "                                               use_label_encoder=False, eval_metric='logloss')\n",
    "            xgb_classifier.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict and evaluate on training data\n",
    "            y_train_pred = xgb_classifier.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "            train_f1 = f1_score(y_train, y_train_pred)\n",
    "            train_recall = recall_score(y_train, y_train_pred)\n",
    "            train_precision = precision_score(y_train, y_train_pred)\n",
    "            \n",
    "            # Predict and evaluate on testing data\n",
    "            y_test_pred = xgb_classifier.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            test_f1 = f1_score(y_test, y_test_pred)\n",
    "            test_recall = recall_score(y_test, y_test_pred)\n",
    "            test_precision = precision_score(y_test, y_test_pred)\n",
    "            \n",
    "            # Calculate elapsed time\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            \n",
    "            # Append training and testing results separately, including parameter values and execution time\n",
    "            params = f'LR: {lr}, Depth: {depth}, Estimators: {n_est}'\n",
    "            \n",
    "            print(params, elapsed_time)\n",
    "            \n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Training',\n",
    "                'Accuracy': train_accuracy,\n",
    "                'F1 Score': train_f1,\n",
    "                'Recall': train_recall,\n",
    "                'Precision': train_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Testing',\n",
    "                'Accuracy': test_accuracy,\n",
    "                'F1 Score': test_f1,\n",
    "                'Recall': test_recall,\n",
    "                'Precision': test_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4af2cb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Data Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Execution Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 20</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.998271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.953316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 20</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.998280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.953316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 50</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.998271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.073009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 50</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.998280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.073009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 100</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999364</td>\n",
       "      <td>0.798331</td>\n",
       "      <td>0.728426</td>\n",
       "      <td>0.883077</td>\n",
       "      <td>1.586185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 100</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999315</td>\n",
       "      <td>0.777143</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>1.586185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 200</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999399</td>\n",
       "      <td>0.812585</td>\n",
       "      <td>0.753807</td>\n",
       "      <td>0.881306</td>\n",
       "      <td>2.588331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 200</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999386</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>0.744898</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>2.588331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 500</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999565</td>\n",
       "      <td>0.865306</td>\n",
       "      <td>0.807107</td>\n",
       "      <td>0.932551</td>\n",
       "      <td>5.996671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 500</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>5.996671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 1000</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999631</td>\n",
       "      <td>0.886486</td>\n",
       "      <td>0.832487</td>\n",
       "      <td>0.947977</td>\n",
       "      <td>12.715235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LR: 0.01, Depth: 3, Estimators: 1000</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>12.715235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LR: 0.01, Depth: 6, Estimators: 20</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.998271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LR: 0.01, Depth: 6, Estimators: 20</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.998280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LR: 0.01, Depth: 6, Estimators: 50</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.998271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.138198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LR: 0.01, Depth: 6, Estimators: 50</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.998280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.138198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LR: 0.01, Depth: 6, Estimators: 100</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999522</td>\n",
       "      <td>0.845390</td>\n",
       "      <td>0.756345</td>\n",
       "      <td>0.958199</td>\n",
       "      <td>1.787553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LR: 0.01, Depth: 6, Estimators: 100</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999421</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>1.787553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LR: 0.01, Depth: 6, Estimators: 200</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999631</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.822335</td>\n",
       "      <td>0.958580</td>\n",
       "      <td>2.992294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LR: 0.01, Depth: 6, Estimators: 200</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>2.992294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Parameters Data Split  Accuracy  F1 Score  \\\n",
       "0     LR: 0.01, Depth: 3, Estimators: 20   Training  0.998271  0.000000   \n",
       "1     LR: 0.01, Depth: 3, Estimators: 20    Testing  0.998280  0.000000   \n",
       "2     LR: 0.01, Depth: 3, Estimators: 50   Training  0.998271  0.000000   \n",
       "3     LR: 0.01, Depth: 3, Estimators: 50    Testing  0.998280  0.000000   \n",
       "4    LR: 0.01, Depth: 3, Estimators: 100   Training  0.999364  0.798331   \n",
       "5    LR: 0.01, Depth: 3, Estimators: 100    Testing  0.999315  0.777143   \n",
       "6    LR: 0.01, Depth: 3, Estimators: 200   Training  0.999399  0.812585   \n",
       "7    LR: 0.01, Depth: 3, Estimators: 200    Testing  0.999386  0.806630   \n",
       "8    LR: 0.01, Depth: 3, Estimators: 500   Training  0.999565  0.865306   \n",
       "9    LR: 0.01, Depth: 3, Estimators: 500    Testing  0.999473  0.831461   \n",
       "10  LR: 0.01, Depth: 3, Estimators: 1000   Training  0.999631  0.886486   \n",
       "11  LR: 0.01, Depth: 3, Estimators: 1000    Testing  0.999579  0.865169   \n",
       "12    LR: 0.01, Depth: 6, Estimators: 20   Training  0.998271  0.000000   \n",
       "13    LR: 0.01, Depth: 6, Estimators: 20    Testing  0.998280  0.000000   \n",
       "14    LR: 0.01, Depth: 6, Estimators: 50   Training  0.998271  0.000000   \n",
       "15    LR: 0.01, Depth: 6, Estimators: 50    Testing  0.998280  0.000000   \n",
       "16   LR: 0.01, Depth: 6, Estimators: 100   Training  0.999522  0.845390   \n",
       "17   LR: 0.01, Depth: 6, Estimators: 100    Testing  0.999421  0.800000   \n",
       "18   LR: 0.01, Depth: 6, Estimators: 200   Training  0.999631  0.885246   \n",
       "19   LR: 0.01, Depth: 6, Estimators: 200    Testing  0.999579  0.862069   \n",
       "\n",
       "     Recall  Precision  Execution Time (s)  \n",
       "0  0.000000   0.000000            0.953316  \n",
       "1  0.000000   0.000000            0.953316  \n",
       "2  0.000000   0.000000            1.073009  \n",
       "3  0.000000   0.000000            1.073009  \n",
       "4  0.728426   0.883077            1.586185  \n",
       "5  0.693878   0.883117            1.586185  \n",
       "6  0.753807   0.881306            2.588331  \n",
       "7  0.744898   0.879518            2.588331  \n",
       "8  0.807107   0.932551            5.996671  \n",
       "9  0.755102   0.925000            5.996671  \n",
       "10 0.832487   0.947977           12.715235  \n",
       "11 0.785714   0.962500           12.715235  \n",
       "12 0.000000   0.000000            0.803240  \n",
       "13 0.000000   0.000000            0.803240  \n",
       "14 0.000000   0.000000            1.138198  \n",
       "15 0.000000   0.000000            1.138198  \n",
       "16 0.756345   0.958199            1.787553  \n",
       "17 0.673469   0.985075            1.787553  \n",
       "18 0.822335   0.958580            2.992294  \n",
       "19 0.765306   0.986842            2.992294  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f14ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('XGBoost_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf38d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1afcaef7",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "To experiment with the AdaBoost algorithm and tweak its parameters, we can adjust the number of estimators (n_estimators) and the learning rate (learning_rate). These are two key parameters for AdaBoost that influence the performance and complexity of the resulting model. The n_estimators parameter controls the number of sequential models to be added to correct the errors of the previous models, while learning_rate scales the contribution of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05d711b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 10, LR: 0.01 31.58523178100586\n",
      "Estimators: 10, LR: 0.1 30.894355535507202\n",
      "Estimators: 10, LR: 0.5 44.40583801269531\n",
      "Estimators: 10, LR: 1 34.184561014175415\n",
      "Estimators: 10, LR: 2 35.3106894493103\n",
      "Estimators: 50, LR: 0.01 167.66188430786133\n",
      "Estimators: 50, LR: 0.1 162.26059937477112\n",
      "Estimators: 50, LR: 0.5 164.6594796180725\n",
      "Estimators: 50, LR: 1 180.01729130744934\n",
      "Estimators: 50, LR: 2 176.27559065818787\n",
      "Estimators: 100, LR: 0.01 335.85931849479675\n",
      "Estimators: 100, LR: 0.1 338.2623703479767\n",
      "Estimators: 100, LR: 0.5 337.5833435058594\n",
      "Estimators: 100, LR: 1 336.3496763706207\n",
      "Estimators: 100, LR: 2 334.9484679698944\n",
      "Estimators: 500, LR: 0.01 1651.756056547165\n",
      "Estimators: 500, LR: 0.1 1727.608912229538\n",
      "Estimators: 500, LR: 0.5 1687.1049993038177\n",
      "Estimators: 500, LR: 1 1728.027375459671\n",
      "Estimators: 500, LR: 2 8401.737571954727\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Instantiate and fit the AdaBoost classifier\u001b[39;00m\n\u001b[0;32m     17\u001b[0m ada_classifier \u001b[38;5;241m=\u001b[39m AdaBoostClassifier(n_estimators\u001b[38;5;241m=\u001b[39mn_estimators, learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m---> 18\u001b[0m ada_classifier\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Predict and evaluate on training data\u001b[39;00m\n\u001b[0;32m     21\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m ada_classifier\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:171\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    168\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost(\n\u001b[0;32m    172\u001b[0m     iboost, X, y, sample_weight, random_state\n\u001b[0;32m    173\u001b[0m )\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:579\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:588\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[0;32m    586\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m--> 588\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m    590\u001b[0m y_predict_proba \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# Define ranges for the parameters to test\n",
    "n_estimators_list = [10, 25, 50, 100] #, 500, 1000, 5000] #Too slow to run all. At 1000 took 4 hours and crashed.\n",
    "learning_rates_list = [0.01, 0.1, 0.5, 1] #, 2]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over the combinations of n_estimators and learning_rates\n",
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rates_list:\n",
    "        start_time = time.time()  # Start timing\n",
    "        \n",
    "        # Instantiate and fit the AdaBoost classifier\n",
    "        ada_classifier = AdaBoostClassifier(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "        ada_classifier.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and evaluate on training data\n",
    "        y_train_pred = ada_classifier.predict(X_train)\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        train_f1 = f1_score(y_train, y_train_pred)\n",
    "        train_recall = recall_score(y_train, y_train_pred)\n",
    "        train_precision = precision_score(y_train, y_train_pred)\n",
    "        \n",
    "        # Predict and evaluate on testing data\n",
    "        y_test_pred = ada_classifier.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        test_f1 = f1_score(y_test, y_test_pred)\n",
    "        test_recall = recall_score(y_test, y_test_pred)\n",
    "        test_precision = precision_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        # Append training and testing results separately, including parameter values and execution time\n",
    "        params = f'Estimators: {n_estimators}, LR: {learning_rate}'\n",
    "        print(params, elapsed_time)\n",
    "        results.append({\n",
    "            'Parameters': params,\n",
    "            'Data Split': 'Training',\n",
    "            'Accuracy': train_accuracy,\n",
    "            'F1 Score': train_f1,\n",
    "            'Recall': train_recall,\n",
    "            'Precision': train_precision,\n",
    "            'Execution Time (s)': elapsed_time\n",
    "        })\n",
    "        results.append({\n",
    "            'Parameters': params,\n",
    "            'Data Split': 'Testing',\n",
    "            'Accuracy': test_accuracy,\n",
    "            'F1 Score': test_f1,\n",
    "            'Recall': test_recall,\n",
    "            'Precision': test_precision,\n",
    "            'Execution Time (s)': elapsed_time\n",
    "        })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c629478",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('AdaBoost_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c292c0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Data Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Execution Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estimators: 10, LR: 0.01</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999100</td>\n",
       "      <td>0.723347</td>\n",
       "      <td>0.680203</td>\n",
       "      <td>0.772334</td>\n",
       "      <td>31.585232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Estimators: 10, LR: 0.01</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999052</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>31.585232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Estimators: 10, LR: 0.1</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.998977</td>\n",
       "      <td>0.623586</td>\n",
       "      <td>0.489848</td>\n",
       "      <td>0.857778</td>\n",
       "      <td>30.894356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estimators: 10, LR: 0.1</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.998947</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>30.894356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estimators: 10, LR: 0.5</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999131</td>\n",
       "      <td>0.701807</td>\n",
       "      <td>0.591371</td>\n",
       "      <td>0.862963</td>\n",
       "      <td>44.405838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Estimators: 10, LR: 0.5</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999175</td>\n",
       "      <td>0.718563</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>44.405838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Estimators: 10, LR: 1</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999149</td>\n",
       "      <td>0.729805</td>\n",
       "      <td>0.664975</td>\n",
       "      <td>0.808642</td>\n",
       "      <td>34.184561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Estimators: 10, LR: 1</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999105</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>34.184561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Estimators: 10, LR: 2</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.355330</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>35.310689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Estimators: 10, LR: 2</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>35.310689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Estimators: 50, LR: 0.01</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>0.683735</td>\n",
       "      <td>0.576142</td>\n",
       "      <td>0.840741</td>\n",
       "      <td>167.661884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Estimators: 50, LR: 0.01</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999070</td>\n",
       "      <td>0.686391</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>167.661884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Estimators: 50, LR: 0.1</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999144</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.583756</td>\n",
       "      <td>0.881226</td>\n",
       "      <td>162.260599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Estimators: 50, LR: 0.1</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999192</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>162.260599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Estimators: 50, LR: 0.5</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999280</td>\n",
       "      <td>0.769014</td>\n",
       "      <td>0.692893</td>\n",
       "      <td>0.863924</td>\n",
       "      <td>164.659480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Estimators: 50, LR: 0.5</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999315</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>164.659480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Estimators: 50, LR: 1</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999307</td>\n",
       "      <td>0.787062</td>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.839080</td>\n",
       "      <td>180.017291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Estimators: 50, LR: 1</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999315</td>\n",
       "      <td>0.784530</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>180.017291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Estimators: 50, LR: 2</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.525381</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>176.275591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Estimators: 50, LR: 2</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>176.275591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Estimators: 100, LR: 0.01</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>0.671851</td>\n",
       "      <td>0.548223</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>335.859318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Estimators: 100, LR: 0.01</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999105</td>\n",
       "      <td>0.687117</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>335.859318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Estimators: 100, LR: 0.1</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999267</td>\n",
       "      <td>0.756914</td>\n",
       "      <td>0.659898</td>\n",
       "      <td>0.887372</td>\n",
       "      <td>338.262370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Estimators: 100, LR: 0.1</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>338.262370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Estimators: 100, LR: 0.5</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999372</td>\n",
       "      <td>0.804378</td>\n",
       "      <td>0.746193</td>\n",
       "      <td>0.872404</td>\n",
       "      <td>337.583344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Estimators: 100, LR: 0.5</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999386</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>0.744898</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>337.583344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Estimators: 100, LR: 1</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999434</td>\n",
       "      <td>0.824966</td>\n",
       "      <td>0.771574</td>\n",
       "      <td>0.886297</td>\n",
       "      <td>336.349676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Estimators: 100, LR: 1</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999350</td>\n",
       "      <td>0.795580</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>336.349676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Estimators: 100, LR: 2</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.174724</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.616751</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>334.948468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Estimators: 100, LR: 2</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.174327</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.540816</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>334.948468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Estimators: 500, LR: 0.01</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999091</td>\n",
       "      <td>0.678072</td>\n",
       "      <td>0.553299</td>\n",
       "      <td>0.875502</td>\n",
       "      <td>1651.756057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Estimators: 500, LR: 0.01</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999192</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1651.756057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Estimators: 500, LR: 0.1</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>0.803324</td>\n",
       "      <td>0.736041</td>\n",
       "      <td>0.884146</td>\n",
       "      <td>1727.608912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Estimators: 500, LR: 0.1</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>1727.608912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Estimators: 500, LR: 0.5</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.880985</td>\n",
       "      <td>0.817259</td>\n",
       "      <td>0.955490</td>\n",
       "      <td>1687.104999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Estimators: 500, LR: 0.5</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.850829</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>1687.104999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Estimators: 500, LR: 1</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.999846</td>\n",
       "      <td>0.953642</td>\n",
       "      <td>0.913706</td>\n",
       "      <td>0.997230</td>\n",
       "      <td>1728.027375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Estimators: 500, LR: 1</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1728.027375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Estimators: 500, LR: 2</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.173456</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.926396</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>8401.737572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Estimators: 500, LR: 2</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.172835</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>8401.737572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Parameters Data Split  Accuracy  F1 Score   Recall  \\\n",
       "0    Estimators: 10, LR: 0.01   Training  0.999100  0.723347 0.680203   \n",
       "1    Estimators: 10, LR: 0.01    Testing  0.999052  0.718750 0.704082   \n",
       "2     Estimators: 10, LR: 0.1   Training  0.998977  0.623586 0.489848   \n",
       "3     Estimators: 10, LR: 0.1    Testing  0.998947  0.615385 0.489796   \n",
       "4     Estimators: 10, LR: 0.5   Training  0.999131  0.701807 0.591371   \n",
       "5     Estimators: 10, LR: 0.5    Testing  0.999175  0.718563 0.612245   \n",
       "6       Estimators: 10, LR: 1   Training  0.999149  0.729805 0.664975   \n",
       "7       Estimators: 10, LR: 1    Testing  0.999105  0.727273 0.693878   \n",
       "8       Estimators: 10, LR: 2   Training  0.000961  0.001229 0.355330   \n",
       "9       Estimators: 10, LR: 2    Testing  0.000966  0.001053 0.306122   \n",
       "10   Estimators: 50, LR: 0.01   Training  0.999078  0.683735 0.576142   \n",
       "11   Estimators: 50, LR: 0.01    Testing  0.999070  0.686391 0.591837   \n",
       "12    Estimators: 50, LR: 0.1   Training  0.999144  0.702290 0.583756   \n",
       "13    Estimators: 50, LR: 0.1    Testing  0.999192  0.722892 0.612245   \n",
       "14    Estimators: 50, LR: 0.5   Training  0.999280  0.769014 0.692893   \n",
       "15    Estimators: 50, LR: 0.5    Testing  0.999315  0.779661 0.704082   \n",
       "16      Estimators: 50, LR: 1   Training  0.999307  0.787062 0.741117   \n",
       "17      Estimators: 50, LR: 1    Testing  0.999315  0.784530 0.724490   \n",
       "18      Estimators: 50, LR: 2   Training  0.001299  0.001816 0.525381   \n",
       "19      Estimators: 50, LR: 2    Testing  0.001194  0.001720 0.500000   \n",
       "20  Estimators: 100, LR: 0.01   Training  0.999074  0.671851 0.548223   \n",
       "21  Estimators: 100, LR: 0.01    Testing  0.999105  0.687117 0.571429   \n",
       "22   Estimators: 100, LR: 0.1   Training  0.999267  0.756914 0.659898   \n",
       "23   Estimators: 100, LR: 0.1    Testing  0.999298  0.767442 0.673469   \n",
       "24   Estimators: 100, LR: 0.5   Training  0.999372  0.804378 0.746193   \n",
       "25   Estimators: 100, LR: 0.5    Testing  0.999386  0.806630 0.744898   \n",
       "26     Estimators: 100, LR: 1   Training  0.999434  0.824966 0.771574   \n",
       "27     Estimators: 100, LR: 1    Testing  0.999350  0.795580 0.734694   \n",
       "28     Estimators: 100, LR: 2   Training  0.174724  0.002578 0.616751   \n",
       "29     Estimators: 100, LR: 2    Testing  0.174327  0.002249 0.540816   \n",
       "30  Estimators: 500, LR: 0.01   Training  0.999091  0.678072 0.553299   \n",
       "31  Estimators: 500, LR: 0.01    Testing  0.999192  0.722892 0.612245   \n",
       "32   Estimators: 500, LR: 0.1   Training  0.999377  0.803324 0.736041   \n",
       "33   Estimators: 500, LR: 0.1    Testing  0.999368  0.795455 0.714286   \n",
       "34   Estimators: 500, LR: 0.5   Training  0.999618  0.880985 0.817259   \n",
       "35   Estimators: 500, LR: 0.5    Testing  0.999526  0.850829 0.785714   \n",
       "36     Estimators: 500, LR: 1   Training  0.999846  0.953642 0.913706   \n",
       "37     Estimators: 500, LR: 1    Testing  0.999508  0.846154 0.785714   \n",
       "38     Estimators: 500, LR: 2   Training  0.173456  0.003861 0.926396   \n",
       "39     Estimators: 500, LR: 2    Testing  0.172835  0.003469 0.836735   \n",
       "\n",
       "    Precision  Execution Time (s)  \n",
       "0    0.772334           31.585232  \n",
       "1    0.734043           31.585232  \n",
       "2    0.857778           30.894356  \n",
       "3    0.827586           30.894356  \n",
       "4    0.862963           44.405838  \n",
       "5    0.869565           44.405838  \n",
       "6    0.808642           34.184561  \n",
       "7    0.764045           34.184561  \n",
       "8    0.000615           35.310689  \n",
       "9    0.000528           35.310689  \n",
       "10   0.840741          167.661884  \n",
       "11   0.816901          167.661884  \n",
       "12   0.881226          162.260599  \n",
       "13   0.882353          162.260599  \n",
       "14   0.863924          164.659480  \n",
       "15   0.873418          164.659480  \n",
       "16   0.839080          180.017291  \n",
       "17   0.855422          180.017291  \n",
       "18   0.000910          176.275591  \n",
       "19   0.000861          176.275591  \n",
       "20   0.867470          335.859318  \n",
       "21   0.861538          335.859318  \n",
       "22   0.887372          338.262370  \n",
       "23   0.891892          338.262370  \n",
       "24   0.872404          337.583344  \n",
       "25   0.879518          337.583344  \n",
       "26   0.886297          336.349676  \n",
       "27   0.867470          336.349676  \n",
       "28   0.001292          334.948468  \n",
       "29   0.001127          334.948468  \n",
       "30   0.875502         1651.756057  \n",
       "31   0.882353         1651.756057  \n",
       "32   0.884146         1727.608912  \n",
       "33   0.897436         1727.608912  \n",
       "34   0.955490         1687.104999  \n",
       "35   0.927711         1687.104999  \n",
       "36   0.997230         1728.027375  \n",
       "37   0.916667         1728.027375  \n",
       "38   0.001935         8401.737572  \n",
       "39   0.001738         8401.737572  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d84e2e",
   "metadata": {},
   "source": [
    "## AdaBoost with Decision Tree clacifier\n",
    "\n",
    "AdaBoost, as implemented in scikit-learn (AdaBoostClassifier), doesn't directly accept a max_depth parameter because AdaBoost can be used with various types of base estimators, not just decision trees. This is a frequent way of using AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242206b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# Define ranges for the parameters to test\n",
    "n_estimators_list = [10, 50, 100, 500, 1000, 5000]\n",
    "learning_rates_list = [0.1, 0.5, 1]\n",
    "max_depths = [3, 6, 9]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over the combinations of n_estimators, learning_rates, and max_depths\n",
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rates_list:\n",
    "        for max_depth in max_depths:\n",
    "            start_time = time.time()  # Start timing\n",
    "            \n",
    "            # Create a DecisionTreeClassifier with the specified max_depth\n",
    "            base_estimator = DecisionTreeClassifier(max_depth=max_depth)\n",
    "            \n",
    "            # Instantiate and fit the AdaBoost classifier with the DecisionTree base estimator\n",
    "            ada_classifier = AdaBoostClassifier(\n",
    "                base_estimator=base_estimator,\n",
    "                n_estimators=n_estimators,\n",
    "                learning_rate=learning_rate\n",
    "            )\n",
    "            ada_classifier.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict and evaluate on training data\n",
    "            y_train_pred = ada_classifier.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "            train_f1 = f1_score(y_train, y_train_pred)\n",
    "            train_recall = recall_score(y_train, y_train_pred)\n",
    "            train_precision = precision_score(y_train, y_train_pred)\n",
    "            \n",
    "            # Predict and evaluate on testing data\n",
    "            y_test_pred = ada_classifier.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            test_f1 = f1_score(y_test, y_test_pred)\n",
    "            test_recall = recall_score(y_test, y_test_pred)\n",
    "            test_precision = precision_score(y_test, y_test_pred)\n",
    "            \n",
    "            # Calculate elapsed time\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            \n",
    "            # Append training and testing results separately, including parameter values and execution time\n",
    "            params = f'Estimators: {n_estimators}, LR: {learning_rate}, Depth: {max_depth}'\n",
    "            print(params, elapsed_time)\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Training',\n",
    "                'Accuracy': train_accuracy,\n",
    "                'F1 Score': train_f1,\n",
    "                'Recall': train_recall,\n",
    "                'Precision': train_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Testing',\n",
    "                'Accuracy': test_accuracy,\n",
    "                'F1 Score': test_f1,\n",
    "                'Recall': test_recall,\n",
    "                'Precision': test_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('AdaboostDT_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Was run in different instance on another similar computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82119b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8198b39c",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machine\n",
    "\n",
    "To perform a similar parameter tweaking experiment with a Gradient Boosting Machine (GBM) using scikit-learn's GradientBoostingClassifier, we can iterate over combinations of n_estimators, learning_rate, and max_depth. These parameters are analogous to those adjusted in the AdaBoost and XGBoost, serving similar purposes:\n",
    "\n",
    "n_estimators: controls the number of sequential trees to be modeled.\n",
    "learning_rate: scales the contribution of each tree.\n",
    "max_depth: sets the maximum depth of each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a1f058c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 10, LR: 0.01, Depth: 3 85.18600678443909\n",
      "Estimators: 10, LR: 0.01, Depth: 6 175.2360532283783\n",
      "Estimators: 10, LR: 0.01, Depth: 9 275.31504702568054\n",
      "Estimators: 10, LR: 0.1, Depth: 3 94.39143300056458\n",
      "Estimators: 10, LR: 0.1, Depth: 6 188.76076078414917\n",
      "Estimators: 10, LR: 0.1, Depth: 9 274.9938325881958\n",
      "Estimators: 10, LR: 0.3, Depth: 3 96.43201422691345\n",
      "Estimators: 10, LR: 0.3, Depth: 6 187.4304609298706\n",
      "Estimators: 10, LR: 0.3, Depth: 9 298.10074400901794\n",
      "Estimators: 50, LR: 0.01, Depth: 3 469.042222738266\n",
      "Estimators: 50, LR: 0.01, Depth: 6 857.1180782318115\n",
      "Estimators: 50, LR: 0.01, Depth: 9 1464.6021127700806\n",
      "Estimators: 50, LR: 0.1, Depth: 3 425.05847239494324\n",
      "Estimators: 50, LR: 0.1, Depth: 6 829.3951048851013\n",
      "Estimators: 50, LR: 0.1, Depth: 9 1250.7942807674408\n",
      "Estimators: 50, LR: 0.3, Depth: 3 418.06535363197327\n",
      "Estimators: 50, LR: 0.3, Depth: 6 840.3917133808136\n",
      "Estimators: 50, LR: 0.3, Depth: 9 1228.5074632167816\n",
      "Estimators: 100, LR: 0.01, Depth: 3 863.3282568454742\n",
      "Estimators: 100, LR: 0.01, Depth: 6 1689.4204423427582\n",
      "Estimators: 100, LR: 0.01, Depth: 9 4479.714942455292\n",
      "Estimators: 100, LR: 0.1, Depth: 3 826.6304256916046\n",
      "Estimators: 100, LR: 0.1, Depth: 6 1665.224750995636\n",
      "Estimators: 100, LR: 0.1, Depth: 9 2604.7517590522766\n",
      "Estimators: 100, LR: 0.3, Depth: 3 973.0924994945526\n",
      "Estimators: 100, LR: 0.3, Depth: 6 1705.5632894039154\n",
      "Estimators: 100, LR: 0.3, Depth: 9 1406.9592308998108\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# Define ranges for the parameters to test\n",
    "n_estimators_list = [10, 50, 100]\n",
    "learning_rates_list = [0.01, 0.1, 0.3]\n",
    "max_depths = [3, 6, 9]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over the combinations of n_estimators, learning_rates, and max_depths\n",
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rates_list:\n",
    "        for max_depth in max_depths:\n",
    "            start_time = time.time()  # Start timing\n",
    "            \n",
    "            # Instantiate and fit the GradientBoostingClassifier\n",
    "            gbm_classifier = GradientBoostingClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                learning_rate=learning_rate,\n",
    "                max_depth=max_depth\n",
    "            )\n",
    "            gbm_classifier.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict and evaluate on training data\n",
    "            y_train_pred = gbm_classifier.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "            train_f1 = f1_score(y_train, y_train_pred)\n",
    "            train_recall = recall_score(y_train, y_train_pred)\n",
    "            train_precision = precision_score(y_train, y_train_pred)\n",
    "            \n",
    "            # Predict and evaluate on testing data\n",
    "            y_test_pred = gbm_classifier.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            test_f1 = f1_score(y_test, y_test_pred)\n",
    "            test_recall = recall_score(y_test, y_test_pred)\n",
    "            test_precision = precision_score(y_test, y_test_pred)\n",
    "            \n",
    "            # Calculate elapsed time\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            \n",
    "            # Append training and testing results separately, including parameter values and execution time\n",
    "            params = f'Estimators: {n_estimators}, LR: {learning_rate}, Depth: {max_depth}'\n",
    "            print(params, elapsed_time)\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Training',\n",
    "                'Accuracy': train_accuracy,\n",
    "                'F1 Score': train_f1,\n",
    "                'Recall': train_recall,\n",
    "                'Precision': train_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "            results.append({\n",
    "                'Parameters': params,\n",
    "                'Data Split': 'Testing',\n",
    "                'Accuracy': test_accuracy,\n",
    "                'F1 Score': test_f1,\n",
    "                'Recall': test_recall,\n",
    "                'Precision': test_precision,\n",
    "                'Execution Time (s)': elapsed_time\n",
    "            })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c78b403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()\n",
    "results_df.to_excel('GBM_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f4c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61ea02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458f0273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb35d33a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5b56d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50bf3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99eb583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2891953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a533f342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deed018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad37cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086b639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ceda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af484487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6217910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
